{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare files for evaluation quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOT VERIFIED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as sps\n",
    "import librosa # 0.7.1\n",
    "import datetime\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAV_FOLDER = \"/Volumes/EAS_ind/mthomas/analysis/resolver_quiz/wavs/\"\n",
    "IMG_FOLDER = \"/Volumes/EAS_ind/mthomas/analysis/resolver_quiz/spec_imgs/\"\n",
    "MATCHES = \"/Volumes/EAS_ind/mthomas/analysis/resolver_quiz/data/candidates_matches.json\"\n",
    "PRED_LABELFILE = \"/Volumes/EAS_ind/mthomas/analysis/resolver_quiz/data/pred_labelfile.pkl\"\n",
    "OUTDIR = \"/Volumes/EAS_ind/mthomas/analysis/resolver_quiz/\"\n",
    "FULL_LABELFILE = \"/Volumes/MaraMeerkat/full_labelfile.pkl\"\n",
    "# File that contains distance scores between call pairs\n",
    "# generated with 02_assign_distances\n",
    "F_NF_FILE = \"/Volumes/EAS_ind/mthomas/analysis/resolver_quiz/data/f_nf.csv\"\n",
    "\n",
    "\n",
    "# From drive\n",
    "WAV_FOLDER = \"/Volumes/MaraMeerkat/resolver_quiz/wavs/\"\n",
    "IMG_FOLDER = \"/Volumes/MaraMeerkat/resolver_quiz/spec_imgs/\"\n",
    "MATCHES = \"/Volumes/MaraMeerkat/candidates_matches.json\"\n",
    "CONTEXT_WAVS='/Volumes/MaraMeerkat/resolver_quiz/context_wavs/'\n",
    "NB_WAVS='/Volumes/MaraMeerkat/resolver_quiz/nb_wavs/'\n",
    "OUTDIR = \"/Volumes/MaraMeerkat/resolver_quiz/\"\n",
    "\n",
    "PRED_LABELFILE = \"/Volumes/MaraMeerkat/pred_labelfile.pkl\"\n",
    "# File that contains distance scores between call pairs\n",
    "# generated with 02_assign_distances\n",
    "F_NF_FILE = \"/Volumes/MaraMeerkat/f_nf.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3193, 38)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read labelfile of all potentially conflicting calls and their predictions\n",
    "labelfile = pd.read_pickle(PRED_LABELFILE)\n",
    "print(labelfile.shape)\n",
    "\n",
    "ids = list(labelfile.callID_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labelfile of all calls\n",
    "full_labelfile = pd.read_pickle(FULL_LABELFILE)\n",
    "full_labelfile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3193"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary of calls and their potential conflicting partners\n",
    "with open(MATCHES, \"r\") as file:  \n",
    "    matches = json.load(file)\n",
    "\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1843\n"
     ]
    }
   ],
   "source": [
    "# list containing all pairs of calls\n",
    "# (non-redundant, i.e. does not contain both [x,y] and [y,x], but only [x,y])\n",
    "\n",
    "all_pairs = []\n",
    "\n",
    "for key in matches.keys():\n",
    "    for val in matches[key]:\n",
    "        if [val,key] not in all_pairs:\n",
    "            all_pairs.append([key, val])\n",
    "        \n",
    "print(len(all_pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_a</th>\n",
       "      <th>call_b</th>\n",
       "      <th>dist_score</th>\n",
       "      <th>intense_a</th>\n",
       "      <th>intense_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20170806_VCVM001_01_11_05_400_0_00_065_sn</td>\n",
       "      <td>20170806_VHMM003_01_10_57_645_0_00_063_sn</td>\n",
       "      <td>0.651184</td>\n",
       "      <td>0.014940</td>\n",
       "      <td>1.198537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20170806_VCVM001_01_11_05_645_0_00_068_sn</td>\n",
       "      <td>20170806_VHMM003_01_10_57_887_0_00_071_sn</td>\n",
       "      <td>0.905537</td>\n",
       "      <td>0.046736</td>\n",
       "      <td>0.412277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20170806_VCVM001_01_11_05_880_0_00_062_sn</td>\n",
       "      <td>20170806_VHMM003_01_10_58_067_0_00_058_sn</td>\n",
       "      <td>0.540828</td>\n",
       "      <td>0.054092</td>\n",
       "      <td>0.948229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20170806_VCVM001_01_11_05_880_0_00_062_sn</td>\n",
       "      <td>20170806_VHMM003_01_10_58_153_0_00_069_sn</td>\n",
       "      <td>0.645326</td>\n",
       "      <td>0.054092</td>\n",
       "      <td>0.742683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20170806_VCVM001_01_12_26_129_0_00_064_sn_x</td>\n",
       "      <td>20170806_VHMM002_01_12_08_899_0_00_066_sn</td>\n",
       "      <td>1.036880</td>\n",
       "      <td>0.087846</td>\n",
       "      <td>0.145992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1838</td>\n",
       "      <td>20190719_VHMM017_01_18_54_428_0_00_161_cc</td>\n",
       "      <td>20190719_VHMM023_01_19_36_532_0_00_147_cc</td>\n",
       "      <td>0.481157</td>\n",
       "      <td>0.342398</td>\n",
       "      <td>1.160400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1839</td>\n",
       "      <td>20190719_VHMM021_01_19_42_491_0_00_172_cc</td>\n",
       "      <td>20190719_VHMM023_01_20_05_843_0_00_161_cc</td>\n",
       "      <td>0.367592</td>\n",
       "      <td>1.163698</td>\n",
       "      <td>0.740246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1840</td>\n",
       "      <td>20190719_VHMM021_01_20_07_584_0_00_146_cc</td>\n",
       "      <td>20190719_VHMM023_01_20_31_056_0_00_123_cc</td>\n",
       "      <td>0.487473</td>\n",
       "      <td>0.951883</td>\n",
       "      <td>1.092899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1841</td>\n",
       "      <td>20190719_VHMM021_01_20_21_300_0_00_123_cc</td>\n",
       "      <td>20190719_VHMM023_01_20_44_677_0_00_150_cc</td>\n",
       "      <td>0.269552</td>\n",
       "      <td>1.181925</td>\n",
       "      <td>0.533275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1842</td>\n",
       "      <td>20190719_VHMM021_01_28_29_568_0_00_165_cc</td>\n",
       "      <td>20190719_VHMM023_01_28_52_214_0_00_159_cc</td>\n",
       "      <td>0.247808</td>\n",
       "      <td>0.934555</td>\n",
       "      <td>0.591248</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1843 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           call_a  \\\n",
       "0       20170806_VCVM001_01_11_05_400_0_00_065_sn   \n",
       "1       20170806_VCVM001_01_11_05_645_0_00_068_sn   \n",
       "2       20170806_VCVM001_01_11_05_880_0_00_062_sn   \n",
       "3       20170806_VCVM001_01_11_05_880_0_00_062_sn   \n",
       "4     20170806_VCVM001_01_12_26_129_0_00_064_sn_x   \n",
       "...                                           ...   \n",
       "1838    20190719_VHMM017_01_18_54_428_0_00_161_cc   \n",
       "1839    20190719_VHMM021_01_19_42_491_0_00_172_cc   \n",
       "1840    20190719_VHMM021_01_20_07_584_0_00_146_cc   \n",
       "1841    20190719_VHMM021_01_20_21_300_0_00_123_cc   \n",
       "1842    20190719_VHMM021_01_28_29_568_0_00_165_cc   \n",
       "\n",
       "                                         call_b  dist_score  intense_a  \\\n",
       "0     20170806_VHMM003_01_10_57_645_0_00_063_sn    0.651184   0.014940   \n",
       "1     20170806_VHMM003_01_10_57_887_0_00_071_sn    0.905537   0.046736   \n",
       "2     20170806_VHMM003_01_10_58_067_0_00_058_sn    0.540828   0.054092   \n",
       "3     20170806_VHMM003_01_10_58_153_0_00_069_sn    0.645326   0.054092   \n",
       "4     20170806_VHMM002_01_12_08_899_0_00_066_sn    1.036880   0.087846   \n",
       "...                                         ...         ...        ...   \n",
       "1838  20190719_VHMM023_01_19_36_532_0_00_147_cc    0.481157   0.342398   \n",
       "1839  20190719_VHMM023_01_20_05_843_0_00_161_cc    0.367592   1.163698   \n",
       "1840  20190719_VHMM023_01_20_31_056_0_00_123_cc    0.487473   0.951883   \n",
       "1841  20190719_VHMM023_01_20_44_677_0_00_150_cc    0.269552   1.181925   \n",
       "1842  20190719_VHMM023_01_28_52_214_0_00_159_cc    0.247808   0.934555   \n",
       "\n",
       "      intense_b  \n",
       "0      1.198537  \n",
       "1      0.412277  \n",
       "2      0.948229  \n",
       "3      0.742683  \n",
       "4      0.145992  \n",
       "...         ...  \n",
       "1838   1.160400  \n",
       "1839   0.740246  \n",
       "1840   1.092899  \n",
       "1841   0.533275  \n",
       "1842   0.591248  \n",
       "\n",
       "[1843 rows x 5 columns]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_nf = pd.read_csv(F_NF_FILE, sep=\"\\t\", index_col=0)\n",
    "f_nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Call wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which are already present, which are missing\n",
    "\n",
    "call_audios = sorted(glob(WAV_FOLDER+'*.wav'))\n",
    "call_ids = [os.path.basename(x).split('.')[0] for x in call_audios]\n",
    "\n",
    "missing = list(list(set(ids)-set(call_ids)))  \n",
    "labelfile_missing = labelfile.loc[labelfile['callID_new'].isin(missing),:]\n",
    "labelfile_missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 8000\n",
    "\n",
    "def write_wav(uid, data, sr):\n",
    "    filename = str(uid)+'.wav'\n",
    "    if sr == SR:\n",
    "        sf.write(filename, data, sr, subtype='PCM_16')\n",
    "    else: # resample\n",
    "        #print(\"Resampled for \"+filename)\n",
    "        number_of_samples = int(round(len(data) * float(SR) / sr))\n",
    "        data = sps.resample(data, number_of_samples)\n",
    "        sf.write(filename, data, SR, subtype='PCM_16')\n",
    "\n",
    "\n",
    "os.chdir(WAV_FOLDER)\n",
    "x=labelfile_missing.apply(lambda row: write_wav(row['callID_new'], row['raw_audio'], row['samplerate_hz']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spec imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which are already present, which are missing\n",
    "\n",
    "imgs = sorted(glob(IMG_FOLDER+'*.jpg'))\n",
    "img_ids = [os.path.basename(x).split('.')[0] for x in imgs]\n",
    "\n",
    "missing = list(list(set(ids)-set(img_ids)))  \n",
    "labelfile_missing = labelfile.loc[labelfile['callID_new'].isin(missing),:]\n",
    "labelfile_missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that pads a spectrogram with zeros to a certain length\n",
    "# Input: spectrogram (2D np array)\n",
    "#        maximal length (Integer)\n",
    "# Output: Padded spectrogram (2D np array)\n",
    "\n",
    "def pad_spectro(spec,maxlen):\n",
    "    padding = maxlen - spec.shape[1]\n",
    "    z = np.zeros((spec.shape[0],padding))\n",
    "    padded_spec=np.append(spec, z, axis=1)\n",
    "    return padded_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "\n",
    "n_ticks=3\n",
    "FFT_WIN = 0.03\n",
    "FFT_HOP = FFT_WIN/8\n",
    "FMAX = 4000\n",
    "MAX_FRAMES = 100 # all specs smaller than that will be padded\n",
    "                 # all specs longer than that will not be affected\n",
    "SR = 8000\n",
    "\n",
    "def write_img(uid, spec, sr):\n",
    "    HOP_LEN = int(0.03*sr) # this is wrong I think\n",
    "    \n",
    "    \n",
    "    outname = str(uid)+\".jpg\" \n",
    "    plt.figure()\n",
    "    \n",
    "    if(spec.shape[1]<MAX_FRAMES):\n",
    "        spec = pad_spectro(spec,MAX_FRAMES)\n",
    "    librosa.display.specshow(spec,sr=sr, hop_length=HOP_LEN , fmax=FMAX, y_axis='mel', cmap='inferno')\n",
    "    n_frames = spec.shape[1]\n",
    "    duration = FFT_HOP*spec.shape[1]\n",
    "    step_size = round(duration/n_ticks,2)\n",
    "    myticks = np.arange(0,duration, step_size)\n",
    "    plt.xticks([round(x/FFT_HOP,0) for x in myticks], [str(round(x,2)) for x in myticks])\n",
    "\n",
    "    pylab.savefig(outname, bbox_inches=None, pad_inches=0)\n",
    "    pylab.close()\n",
    "\n",
    "os.chdir(IMG_FOLDER)\n",
    "\n",
    "x=labelfile_missing.apply(lambda row: write_img(row['callID_new'],\n",
    "                                        row['denoised_spectrograms'],\n",
    "                                        row['samplerate_hz']), \n",
    "                      axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Context wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1376"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check which are already present, which are missing\n",
    "\n",
    "CONTEXT_WAVS='/Volumes/MaraMeerkat/resolver_quiz/context_wavs/'\n",
    "context_audios = sorted(glob(CONTEXT_WAVS+'*.wav'))\n",
    "context_ids = [os.path.basename(x).split('.')[0] for x in context_audios]\n",
    "\n",
    "missing = list(list(set(ids)-set(context_ids)))  \n",
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load wavdict:\n",
    "with open(\"/Volumes/MaraMeerkat/wav_dict.json\", \"r\") as file:  \n",
    "    wav_dict = json.load(file)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Previously:)\n",
    "\n",
    "# make wavdict of needed wavs\n",
    "wavs_we_need = list(set(list(full_labelfile.wavFileName)))\n",
    "AUDIOS_PATH = \"/Volumes/EAS_shared/meerkat/archive/rawdata/MEERKAT_RAW_DATA\"\n",
    "\n",
    "# Add column with linking a path to the actual wav file on the server\n",
    "# that we need in order to extract that call bout\n",
    "\n",
    "# list all filepaths to all available wav files on the server\n",
    "listOfFiles = list()\n",
    "for r, d, f in os.walk(AUDIOS_PATH):\n",
    "    for file in f:\n",
    "        if (file.endswith(\".wav\") or file.endswith(\".WAV\")):\n",
    "            if file[0]!=\".\":\n",
    "                listOfFiles.append(os.path.join(r, file))\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "# Create dictionary\n",
    "wav_matches = []\n",
    "no_wav_path = []\n",
    "\n",
    "# Now assign a wav filename to each csv_filename\n",
    "for wav in wavs_we_need:\n",
    "    # Search corresponding wav\n",
    "    matches = [x for x in listOfFiles if wav in x]\n",
    "    if(len(matches)==0):\n",
    "        no_wav_path.append(wav)\n",
    "        matches = \"NA\"\n",
    "    wav_matches.append(matches)\n",
    "    \n",
    "# Unlist all to string and choose first match in case there are multiple\n",
    "wav_matches = [x if type(x)==str else x[0] for x in wav_matches]\n",
    "wav_dict = dict(zip(wavs_we_need, wav_matches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save wavdict\n",
    "\n",
    "with open('/Volumes/MaraMeerkat/'+\"wav_dict.json\", \"w\") as outfile:  \n",
    "    json.dump(wav_dict, outfile) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_time(timestring):    \n",
    "    time_patterns = ['%H:%M:%S.%f', '%M:%S.%f']\n",
    "    \n",
    "    if(timestring)==0:\n",
    "        return datetime.datetime.strptime('0:00:00.00', '%H:%M:%S.%f')\n",
    "    else:\n",
    "        for pattern in time_patterns:\n",
    "            try:\n",
    "                return datetime.datetime.strptime(timestring, pattern)\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "        print(\"Date is not in expected format\") \n",
    "        print(timestring)\n",
    "        sys.exit(0)\n",
    "\n",
    "def get_s(dt):\n",
    "    return dt.microsecond/1000000+dt.second + dt.minute*60 + dt.hour*60*60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 8000\n",
    "OUTDIR = CONTEXT_WAVS\n",
    "\n",
    "for call in missing:\n",
    "    wavFile = full_labelfile.loc[full_labelfile.callID_new==call,'wavFileName'].values[0]\n",
    "    wavloc = wav_dict[wavFile]\n",
    "    \n",
    "    start_s = get_s(get_time(full_labelfile.loc[full_labelfile.callID_new==call,'t0File'].values[0]))-5\n",
    "    duration_s = 10\n",
    "    \n",
    "    data, sr = librosa.load(wavloc, offset=start_s, duration=duration_s, sr=None)\n",
    "    \n",
    "    filename = call+'.wav'\n",
    "    if sr == SR:\n",
    "        sf.write(OUTDIR+filename, data, sr, subtype='PCM_16')\n",
    "    else: # resample\n",
    "        number_of_samples = int(round(len(data) * float(SR) / sr))\n",
    "        data = sps.resample(data, number_of_samples)\n",
    "        sf.write(OUTDIR+filename, data, SR, subtype='PCM_16')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NB calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which are already present, which are missing\n",
    "\n",
    "nb_audios = sorted(glob(NB_WAVS+'*.wav'))\n",
    "nb_ids = [os.path.basename(x).split('.')[0] for x in nb_audios]\n",
    "\n",
    "missing = list(list(set(ids)-set(nb_ids)))  \n",
    "len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 8000\n",
    "\n",
    "def write_wav(uid, data, sr):\n",
    "    filename = str(uid)+'.wav'\n",
    "    if sr == SR:\n",
    "        sf.write(filename, data, sr, subtype='PCM_16')\n",
    "    else: # resample\n",
    "        #print(\"Resampled for \"+filename)\n",
    "        number_of_samples = int(round(len(data) * float(SR) / sr))\n",
    "        data = sps.resample(data, number_of_samples)\n",
    "        sf.write(filename, data, SR, subtype='PCM_16')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(NB_WAVS)\n",
    "\n",
    "n_compare = 3 # calls before and after\n",
    "\n",
    "for call in missing: \n",
    "    #print(call)\n",
    "    data = []\n",
    "    # find recording filename\n",
    "    wavFile = full_labelfile.loc[full_labelfile.callID_new==call,'wavFileName'].values[0]\n",
    "    \n",
    "    # select all calls in that recording\n",
    "    sub_df = full_labelfile.loc[full_labelfile.wavFileName==wavFile,:]\n",
    "    # select only focal\n",
    "    sub_df = sub_df.loc[sub_df.nonFocal==0,:]\n",
    "\n",
    "    # make sure it's sorted by t0 GPS time\n",
    "    sub_df['date'] = pd.to_datetime(sub_df['t0GPS_UTC'])\n",
    "    sub_df = sub_df.sort_values(by='date')\n",
    "\n",
    "    # reset index\n",
    "    sub_df.reset_index(inplace=True)\n",
    "    \n",
    "    # find call index\n",
    "    call_index = sub_df.loc[sub_df.callID_new==call,:].index[0]\n",
    "\n",
    "    # border cases, where call is at very beginning or end of recording file\n",
    "    if call_index<n_compare:\n",
    "        n_left = call_index\n",
    "        n_right = n_compare*2 - n_left\n",
    "    elif ((sub_df.shape[0]-call_index-1)<n_compare):\n",
    "        n_right = sub_df.shape[0]-call_index-1\n",
    "        n_left = n_compare*2 - n_right\n",
    "    \n",
    "    # base case:\n",
    "    else:\n",
    "        n_left = n_compare\n",
    "        n_right = n_compare\n",
    "          \n",
    "    sr = full_labelfile.loc[full_labelfile.callID_new==call,'samplerate_hz'].values[0]\n",
    "    filler = np.zeros((sr)) # fill with 1s of silence\n",
    "    \n",
    "    for nb_index in range(call_index-n_left, call_index):\n",
    "        nb_call = sub_df.iloc[nb_index,:].callID_new\n",
    "        data=data+list(filler)+list(sub_df.iloc[nb_index-i,:].raw_audio)\n",
    "\n",
    "    for nb_index in range(call_index+1, call_index+1+n_right):\n",
    "        nb_call = sub_df.iloc[nb_index,:].callID_new\n",
    "        data=data+list(filler)+list(sub_df.iloc[nb_index,:].raw_audio)\n",
    "   \n",
    "    write_wav(call, np.asarray(data), sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

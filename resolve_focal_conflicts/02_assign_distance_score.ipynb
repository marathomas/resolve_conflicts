{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign distance score\n",
    "\n",
    "Script to assign distance scores to call pairs using spectrogram comparison. \n",
    "Requirements:\n",
    "- \"candidates_matches.json\", containing all potential matches (generated with 01_identify_focal_conflicts)\n",
    "- \"candidates_labelfile.csv\" of all calls involved in a match (generated with 01_identify_focal_conflicts)\n",
    "- \"txts/\" folder containing audio data for all calls (generated with 00_1_extract_calls)\n",
    "\n",
    "Output:\n",
    "- a csv file containing all pairs of calls and their respective spectrogram distance, intensity and physical distance scores (\"f_nf.csv\"), saved in EAS_shared/.../resolve_conflicts.\n",
    "- may update \"candidates_labelfile.csv\" and \"candidates_matches.json\" if audio for calls can't be found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Get audio and spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import librosa\n",
    "import sys\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy import stats\n",
    "import math\n",
    "from scipy.signal import butter, lfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('server_path.txt', \"r\")\n",
    "SERVER = f.read().strip()\n",
    "f.close()\n",
    "\n",
    "HOME = SERVER + os.path.join(os.path.sep, 'EAS_shared',\n",
    "                             'meerkat','working','processed',\n",
    "                             'acoustic', 'resolve_conflicts')\n",
    "\n",
    "# location of candidate files generated with 01_identify_focal_conflicts\n",
    "CANDIDATES_MATCHES = os.path.join(os.path.sep, HOME,'candidates_matches.json')\n",
    "CANDIDATES_LABELFILE = os.path.join(os.path.sep, HOME,'candidates_labelfile.csv')\n",
    "\n",
    "# location of audio txt files generated with 00_1_generate_call_txts\n",
    "TXT_PATH = SERVER + os.path.join(os.path.sep, 'EAS_shared',\n",
    "                             'meerkat','working','processed',\n",
    "                             'acoustic', 'extract_calls', 'txts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogramming parameters\n",
    "FFT_WIN = 0.03 # FFT_WIN*samplerate = length of fft/n_fft (number of audio frames that go in one fft)\n",
    "FFT_HOP = FFT_WIN/8 # FFT_HOP*samplerate = n of audio frames between successive ffts\n",
    "N_MELS = 40 # number of mel bins\n",
    "WINDOW = 'hann' # each frame of audio is windowed by a window function (its length can also be\n",
    "# determined and is then padded with zeros to match n_fft. we use window_length = length of fft\n",
    "FMAX = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_wav_txt(filename):    \n",
    "    \"\"\"\n",
    "    Function that reads audio data and sr from audio\n",
    "    saved in txt format\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: String\n",
    "          path to txt file\n",
    "          \n",
    "    Returns\n",
    "    -------\n",
    "    data : 1D np.array\n",
    "           Raw audio data (Amplitude)\n",
    "           \n",
    "    sr: numeric (Integer)\n",
    "        Samplerate (in Hz)\n",
    "    \"\"\"\n",
    "    data = np.asarray([0])\n",
    "    sr = 0\n",
    "    \n",
    "    try:\n",
    "        f = open(filename, 'r')\n",
    "        lines = f.readlines()\n",
    "        lines = [line.strip() for line in lines]\n",
    "\n",
    "        sr = int(lines[0].split(':')[1])\n",
    "        data = np.asarray([float(x) for x in lines[1:]])\n",
    "        \n",
    "        f.close()\n",
    "        \n",
    "    except Exception:\n",
    "        print(\"No such file or directory: \", filename)\n",
    "        pass\n",
    "    return data, sr\n",
    "\n",
    "\n",
    "def generate_mel_spectrogram(data, rate, n_mels, window, fft_win , fft_hop):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that generates mel spectrogram from audio data using librosa functions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: 1D numpy array (float)\n",
    "          Audio data\n",
    "    rate: numeric(integer)\n",
    "          samplerate in Hz\n",
    "    n_mels: numeric (integer)\n",
    "            number of mel bands\n",
    "    window: string\n",
    "            spectrogram window generation type ('hann'...)\n",
    "    fft_win: numeric (float)\n",
    "             window length in s\n",
    "    fft_hop: numeric (float)\n",
    "             hop between window start in s \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : 2D np.array\n",
    "             Mel-transformed spectrogram\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> \n",
    "    \n",
    "    \"\"\"\n",
    "    n_fft  = int(fft_win * rate) \n",
    "    hop_length = int(fft_hop * rate) \n",
    "        \n",
    "    s = librosa.feature.melspectrogram(y = data ,\n",
    "                                       sr = rate, \n",
    "                                       n_mels = n_mels , \n",
    "                                       fmax = FMAX, \n",
    "                                       n_fft = n_fft,\n",
    "                                       hop_length = hop_length, \n",
    "                                       window = window, \n",
    "                                       win_length = n_fft)\n",
    "\n",
    "    spectro = librosa.power_to_db(s, ref=np.max)\n",
    "\n",
    "    return spectro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4270, 9)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelfile = pd.read_csv(CANDIDATES_LABELFILE, sep=\"\\t\")\n",
    "labelfile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching audio data for  4270  calls...\n"
     ]
    }
   ],
   "source": [
    "print(\"Fetching audio data for \", labelfile.shape[0], \" calls...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "audios_we_need = [os.path.join(os.path.sep, TXT_PATH, x+'.txt') for x in labelfile.callID_new]\n",
    "raw_audio,samplerate_hz = map(list,zip(*[read_wav_txt(x) for x in audios_we_need]))\n",
    "\n",
    "labelfile['raw_audio'] = raw_audio\n",
    "labelfile['samplerate_hz'] = samplerate_hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If there are any calls where no audio data was found, remove these from the labelfile and from matches\n",
    "\n",
    "# Which IDs are missing?\n",
    "missing = []\n",
    "for audio, callID in zip(labelfile.raw_audio, labelfile.callID_new):\n",
    "    if audio.shape[0]==1:\n",
    "        missing.append(callID)\n",
    "\n",
    "if len(missing)!=0:\n",
    "    # remove missing from labelfile\n",
    "    labelfile = labelfile.loc[~(labelfile['callID_new'].isin(missing)),:]\n",
    "    \n",
    "    # remove missing from matches\n",
    "    with open(CANDIDATES_MATCHES, \"r\") as file:\n",
    "        cand_matches = json.load(file)\n",
    "    \n",
    "    matches = {}    \n",
    "\n",
    "    # remove the missing calls in the keys\n",
    "    for key in cand_matches.keys():\n",
    "        if key not in missing:\n",
    "            # then remove any missing calls that are present as match partners\n",
    "            match_partners = [p for p in cand_matches[key] if p not in missing]\n",
    "            if len(match_partners)!=0:\n",
    "                matches[key] = match_partners\n",
    "\n",
    "    # save corrected candidate_matches and labelfile\n",
    "    with open(CANDIDATES_MATCHES, \"w\") as outfile:  \n",
    "        json.dump(matches, outfile) \n",
    "    \n",
    "    labelfile.to_csv(CANDIDATES_LABELFILE, sep=\"\\t\", index=False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found audio data for  4270  calls\n"
     ]
    }
   ],
   "source": [
    "print(\"Found audio data for \", labelfile.shape[0], \" calls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate spectrograms\n",
    "\n",
    "spectrograms = labelfile.apply(lambda row: generate_mel_spectrogram(row['raw_audio'],\n",
    "                                                                    row['samplerate_hz'],\n",
    "                                                                    N_MELS,\n",
    "                                                                    WINDOW,\n",
    "                                                                    FFT_WIN,\n",
    "                                                                    FFT_HOP), \n",
    "                               axis=1)\n",
    "\n",
    "\n",
    "labelfile['spectrograms'] = spectrograms\n",
    "\n",
    "denoised = [(spectrogram - np.median(spectrogram, axis=0)) for spectrogram in labelfile['spectrograms']]\n",
    "labelfile['denoised_spectrograms'] = denoised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Assign distance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.common import flatten\n",
    "from scipy import stats\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template matching parameters\n",
    "\n",
    "N_RANDOM_SHUFFLE = 10 # times to randomly shuffle spectrogram for normalization\n",
    "MIN_OVERLAP = 0.9 # short spectrogram has to have at least MIN_OVERLAP with longer spectrogram\n",
    "MAX_F_SHIFT = 0 # max frequency shift allowed when comparing spectrograms (in mel bins)\n",
    "                # Left this in here for the future, but since it's set to zero, I am not allowing \n",
    "                # frequency shift at the moment\n",
    "N_MELS=40 # N_Mels present\n",
    "MEL_BINS_REMOVED_LOWER = 5 # remove lowest MEL_BINS_REMOVED_LOWER mel bins from \n",
    "                           # spectrograms (~all below 300 Hz), probably noise\n",
    "MEL_BINS_REMOVED_UPPER = 5 # remove upmost MEL_BINS_REMOVED_UPPER mel bins from\n",
    "                           # spectrograms (~all above 3 kHz), probably noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4270"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary of calls and their potential conflicting partners\n",
    "\n",
    "with open(CANDIDATES_MATCHES, \"r\") as file:  \n",
    "    matches = json.load(file)\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2676\n"
     ]
    }
   ],
   "source": [
    "# list containing all pairs of calls\n",
    "# (non-redundant, i.e. does not contain both [x,y] and [y,x], but only [x,y])\n",
    "\n",
    "all_pairs = []\n",
    "\n",
    "for key in matches.keys():\n",
    "    for val in matches[key]:\n",
    "        if [val,key] not in all_pairs:\n",
    "            all_pairs.append([key, val])\n",
    "        \n",
    "print(len(all_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate spectrogram dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_dist(s_1, s_2):\n",
    "    \"\"\"\n",
    "    Basic spectrogram distance function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s_1, s_2: 2D np.arrays\n",
    "              the two spectrograms to compare\n",
    "          \n",
    "    Returns\n",
    "    -------   \n",
    "    norm_dist: numeric (Float)\n",
    "               Squared error between specs s_1, s_2\n",
    "               normalized to randomized sq. error \n",
    "               between s_1, s_2\n",
    "    \"\"\"\n",
    "    dist = np.sum((np.subtract(s_1, s_2)*np.subtract(s_1, s_2)), axis=None)\n",
    "    \n",
    "    # Normalize to random shuffling\n",
    "    random_dist = calc_random_dist(s_1,s_2)\n",
    "    norm_dist = dist / random_dist \n",
    "    \n",
    "    return norm_dist\n",
    "\n",
    "def calc_random_dist(s_1, s_2):\n",
    "    \"\"\"\n",
    "    Helper for basic spectrogram distance function\n",
    "    Calculates randomized sq error between two\n",
    "    spectrograms s_1, s_2 by shuffling s_1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s_1, s_2: 2D np.arrays\n",
    "              the two spectrograms to compare         \n",
    "    Returns\n",
    "    -------   \n",
    "        numeric (Float)\n",
    "        Randomized sq. error between s_1, s_2\n",
    "    \"\"\"\n",
    "    dists = []\n",
    "    s_1_shuffled = np.copy(s_1)\n",
    "    for i in range(N_RANDOM_SHUFFLE):\n",
    "        np.random.shuffle(s_1_shuffled)\n",
    "        dists.append(np.sum((np.subtract(s_1_shuffled, s_2)*np.subtract(s_1_shuffled, s_2)), axis=None)) \n",
    "    return(np.mean(dists))   \n",
    "\n",
    "def calc_mindist(spec_a, spec_b):\n",
    "    \"\"\"\n",
    "    Calculate min distance between two specs s_1, s_2\n",
    "    by shifting specs against each other along time and \n",
    "    freq axis with certain global constraints\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spec_a, spec_b: 2D np.arrays\n",
    "                    the two spectrograms to compare         \n",
    "    Returns\n",
    "    -------   \n",
    "    min_dist: numeric (Float)\n",
    "              Minimum distance (produced by the best \n",
    "              overlap)\n",
    "    \"\"\"\n",
    "    # Find the bigger spec\n",
    "    spec_list = [spec_a, spec_b]\n",
    "    spec_lens = [s.shape[1] for s in spec_list]\n",
    "    \n",
    "    if spec_a.shape[1]==spec_b.shape[1]:\n",
    "        spec_s = spec_a\n",
    "        len_s = spec_s.shape[1]\n",
    "        spec_l = spec_b\n",
    "        len_l = len_s\n",
    "    else:\n",
    "        spec_s = spec_list[np.argmin(spec_lens)] # shorter spec\n",
    "        len_s = np.min(spec_lens)\n",
    "        spec_l = spec_list[np.argmax(spec_lens)] # longer spec\n",
    "        len_l = np.max(spec_lens)\n",
    "\n",
    "    # define start position for time shifting\n",
    "    # based on MIN_OVERLAP\n",
    "    min_overlap_frames = int(MIN_OVERLAP * len_s)\n",
    "    start_timeline = min_overlap_frames-len_s\n",
    "    max_timeline = len_l - min_overlap_frames\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    # shift short spec across longer, one time frame\n",
    "    # at a time. Only compare the overlap section\n",
    "    for timeline_p in range(start_timeline, max_timeline+1):\n",
    "        # Select full specs or only a subset (start_col to end_col), \n",
    "        # depending on any of the three cases:\n",
    "        \n",
    "        # 1) mismatch on left side\n",
    "        if timeline_p < 0:\n",
    "            start_col_l = 0\n",
    "            len_overlap = len_s - abs(timeline_p)\n",
    "            end_col_l = start_col_l + len_overlap\n",
    "\n",
    "            end_col_s = len_s # until the end\n",
    "            start_col_s = end_col_s - len_overlap\n",
    "\n",
    "        # 2) mismatch on right side\n",
    "        elif timeline_p > (len_l-len_s):\n",
    "            start_col_l = timeline_p\n",
    "            len_overlap = len_l - timeline_p\n",
    "            end_col_l = len_l\n",
    "\n",
    "            start_col_s = 0\n",
    "            end_col_s = start_col_s + len_overlap\n",
    "\n",
    "        # 3) no mismatch on either side\n",
    "        else:\n",
    "            start_col_l = timeline_p\n",
    "            len_overlap = len_s\n",
    "            end_col_l = start_col_l + len_overlap\n",
    "\n",
    "            start_col_s = 0\n",
    "            end_col_s = len_s \n",
    "        \n",
    "        s_s = spec_s[:,start_col_s:end_col_s] \n",
    "        s_l = spec_l[:,start_col_l:end_col_l] \n",
    "        distances.append(spec_dist(s_s, s_l))\n",
    "        \n",
    "        # Now do frequency shift\n",
    "        \n",
    "        # move smaller spec UP\n",
    "        for fshift in range(1,MAX_F_SHIFT+1):\n",
    "            s_s_fshifted = s_s[fshift:,:] # remove lowest freq row(s) from s_s\n",
    "            s_l_fshifted = s_l[:-fshift,:] # remove highest freq row(s) from s_l\n",
    "            \n",
    "            distances.append(spec_dist(s_s_fshifted, s_l_fshifted))\n",
    "        \n",
    "        # move smaller spec DOWN\n",
    "        for fshift in range(1,MAX_F_SHIFT+1):\n",
    "            s_s_fshifted = s_s[:-fshift,:] # remove highest freq row(s) from s_s\n",
    "            s_l_fshifted = s_l[fshift:,:]  # remove lowest freq row(s) from s_l\n",
    "            \n",
    "            distances.append(spec_dist(s_s_fshifted, s_l_fshifted))            \n",
    "        \n",
    "\n",
    "    min_dist = np.min(distances)\n",
    "    return min_dist\n",
    "\n",
    "def preprocess_spec(spec):\n",
    "    \"\"\"\n",
    "    Do some transformations with denoised mel-spectrogram \n",
    "    to improve information content for template matching\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spec: 2D np.array\n",
    "          a denoised mel-spectrogram      \n",
    "    \n",
    "    Returns\n",
    "    -------   \n",
    "    spec: 2D np.array\n",
    "          the transformed, denoised mel-spectrogram         \n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove MEL_BINS_REMOVED_UPPER and -LOWER mels\n",
    "    spec = spec[MEL_BINS_REMOVED_LOWER:(N_MELS-MEL_BINS_REMOVED_UPPER),:]\n",
    "\n",
    "    # Z-score normalize\n",
    "    spec = stats.zscore(spec, axis=None)\n",
    "    \n",
    "    # Cap vals > 3 STD higher than mean (intense=intense)\n",
    "    spec = np.where(spec > 3, 3, spec)\n",
    "    \n",
    "    #  Cap vals lower than mean to 0\n",
    "    spec = np.where(spec < 0, 0, spec)\n",
    "    \n",
    "    return spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning distance scores...\n"
     ]
    }
   ],
   "source": [
    "print(\"Assigning distance scores...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dict = dict(zip(labelfile.callID_new.values, labelfile.denoised_spectrograms.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists=[]\n",
    "\n",
    "for pair in all_pairs:\n",
    "    spec = preprocess_spec(spec_dict[pair[0]])\n",
    "    nb_spec = preprocess_spec(spec_dict[pair[1]])\n",
    "    dist = calc_mindist(spec, nb_spec)\n",
    "    dists.append(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "f_nf = pd.DataFrame({'call_a': [x[0] for x in all_pairs],\n",
    "                    'call_b' : [x[1] for x in all_pairs],\n",
    "                    'dist_score' : dists})\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate audio intensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bandpass filters for calculating audio intensity\n",
    "LOWCUT = 300.0\n",
    "HIGHCUT = 3000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates intensity score from \n",
    "# amplitude audio data\n",
    "# Input: 1D numeric numpy array (audio data)\n",
    "# Output: Float (Intensity)\n",
    "def calc_audio_intense_score(audio):\n",
    "    res = 10*math.log((np.mean(audio**2)),10)\n",
    "    return res\n",
    "\n",
    "# Butter bandpass filter implementation:\n",
    "# from https://scipy-cookbook.readthedocs.io/items/ButterworthBandpass.html\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning intensity scores...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Assigning intensity scores...\")\n",
    "\n",
    "# Using the band-pass filtered signal! \n",
    "\n",
    "clean_intensity = []\n",
    "\n",
    "for call in list(labelfile.callID_new):\n",
    "    audio = list(labelfile.loc[labelfile.callID_new==call,'raw_audio'])[0]\n",
    "    sr = list(labelfile.loc[labelfile.callID_new==call,'samplerate_hz'])[0]\n",
    "    y = butter_bandpass_filter(audio, LOWCUT, HIGHCUT, sr, order=6)\n",
    "    clean_intensity.append(calc_audio_intense_score(y))\n",
    "\n",
    "labelfile['intense_score'] = clean_intensity\n",
    "intense_dict = dict(zip(labelfile.callID_new.values, labelfile.intense_score.values))\n",
    "\n",
    "f_nf['intense_a'] = [intense_dict[x] for x in f_nf.call_a]\n",
    "f_nf['intense_b'] = [intense_dict[x] for x in f_nf.call_b]\n",
    "\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculate physical distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dist_2d(x1,y1,x2,y2):\n",
    "    dist = math.sqrt((x1-x2)**2 + (y1-y2)**2)\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning physical distance scores...\n",
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Assigning physical distance scores...\")\n",
    "\n",
    "physical_dist = []\n",
    "\n",
    "for i in range(f_nf.shape[0]):\n",
    "    call = f_nf.loc[i,'call_a']    \n",
    "    x1 = float(labelfile.loc[labelfile.callID_new==call,'x_emitted'])\n",
    "    y1 = float(labelfile.loc[labelfile.callID_new==call,'y_emitted'])\n",
    "    \n",
    "    call = f_nf.loc[i,'call_b'] \n",
    "    x2 = float(labelfile.loc[labelfile.callID_new==call,'x_emitted'])\n",
    "    y2 = float(labelfile.loc[labelfile.callID_new==call,'y_emitted'])\n",
    "    \n",
    "    if np.isnan([x1,y1,x2,y2]).any()==True:\n",
    "        d = np.nan \n",
    "    else:\n",
    "        d = dist_2d(x1,y1,x2,y2)\n",
    "        \n",
    "    physical_dist.append(d)\n",
    "    \n",
    "f_nf['physical_dist'] = physical_dist\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save f_nf file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed.\n"
     ]
    }
   ],
   "source": [
    "f_nf_out = os.path.join(os.path.sep, HOME,'f_nf.csv')\n",
    "f_nf.to_csv(f_nf_out, sep=\"\\t\", index=False)\n",
    "\n",
    "print(\"Completed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

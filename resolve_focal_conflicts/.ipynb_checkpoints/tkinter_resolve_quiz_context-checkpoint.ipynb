{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "from tkinter import Tk, Frame, Label, Button, Entry\n",
    "from pygame import mixer\n",
    "from PIL import ImageTk, Image\n",
    "from glob import glob\n",
    "from pandas.core.common import flatten\n",
    "import tkinter as tk\n",
    "\n",
    "from IPython.display import Audio\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial import distance\n",
    "from scipy import stats\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Froms server\n",
    "WAV_FOLDER = \"/Volumes/EAS_ind/mthomas/analysis/resolver_quiz/wavs/\"\n",
    "IMG_FOLDER = \"/Volumes/EAS_ind/mthomas/analysis/resolver_quiz/spec_imgs/\"\n",
    "MATCHES = \"/Volumes/EAS_ind/mthomas/analysis/resolver_quiz/data/candidates_matches.json\"\n",
    "PRED_LABELFILE = \"/Volumes/EAS_ind/mthomas/analysis/resolver_quiz/data/pred_labelfile.pkl\"\n",
    "OUTDIR = \"/Volumes/EAS_ind/mthomas/analysis/resolver_quiz/\"\n",
    "# File that contains distance scores between call pairs\n",
    "# generated with 02_assign_distances\n",
    "F_NF_FILE = \"/Volumes/EAS_ind/mthomas/analysis/resolver_quiz/data/f_nf.csv\"\n",
    "\n",
    "\n",
    "# From drive\n",
    "WAV_FOLDER = \"/Volumes/MaraMeerkat/resolver_quiz/wavs/\"\n",
    "IMG_FOLDER = \"/Volumes/MaraMeerkat/resolver_quiz/spec_imgs/\"\n",
    "MATCHES = \"/Volumes/MaraMeerkat/candidates_matches.json\"\n",
    "log2dict_FILE = \"/Volumes/MaraMeerkat/log2dict.json\"\n",
    "PRED_LABELFILE = \"/Volumes/MaraMeerkat/pred_labelfile.pkl\"\n",
    "OUTDIR = \"/Volumes/MaraMeerkat/resolver_quiz/\"\n",
    "# File that contains distance scores between call pairs\n",
    "# generated with 02_assign_distances\n",
    "F_NF_FILE = \"/Volumes/MaraMeerkat/f_nf.csv\"\n",
    "CONTEXT_WAVS = \"/Volumes/MaraMeerkat/resolver_quiz/context_wavs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3193, 38)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelfile = pd.read_pickle(PRED_LABELFILE)\n",
    "labelfile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3193"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(MATCHES, \"r\") as file:  \n",
    "    matches = json.load(file)   \n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pairs = [[x,y] for x,y in zip(matches.keys(), matches.values())]\n",
    "f_nf = pd.read_csv(F_NF_FILE, sep=\"\\t\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make audio dict\n",
    "audios = sorted(glob(WAV_FOLDER+'*.wav'))\n",
    "ids = [os.path.basename(x).split('.')[0] for x in audios]\n",
    "audio_dict = dict(zip(ids, audios))\n",
    "\n",
    "# Make imgs dict\n",
    "imgs = sorted(glob(IMG_FOLDER+'*.jpg'))\n",
    "ids = [os.path.basename(x).split('.')[0] for x in imgs]\n",
    "img_dict = dict(zip(ids, imgs))\n",
    "\n",
    "# Make spectrogram dict\n",
    "spec_dict = dict(zip(labelfile.callID_new, labelfile.denoised_spectrograms)) \n",
    "\n",
    "# Context calls \n",
    "CONTEXT_WAVS='/Volumes/MaraMeerkat/resolver_quiz/background_wavs/'\n",
    "context_audios = sorted(glob(CONTEXT_WAVS+'*.wav'))\n",
    "ids = [os.path.basename(x).split('.')[0] for x in context_audios]\n",
    "context_audio_dict = dict(zip(ids, context_audios))\n",
    "\n",
    "# Pred_dict\n",
    "pred_dict = dict(zip(labelfile.callID_new, labelfile.pred_nonFocal)) \n",
    "pred_why_dict = dict(zip(labelfile.callID_new, labelfile.pred_why)) \n",
    "pred_comment = dict(zip(labelfile.callID_new, labelfile.pred_comment)) \n",
    "\n",
    "# Intense_dict\n",
    "intense_dict = {}\n",
    "for call in f_nf.call_a:\n",
    "    if call not in intense_dict.keys():\n",
    "        intense_dict[call] = f_nf.loc[f_nf['call_a']==call,'intense_a'].values[0]\n",
    "for call in f_nf.call_b:\n",
    "    if call not in intense_dict.keys():\n",
    "        intense_dict[call] = f_nf.loc[f_nf['call_b']==call,'intense_b'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3193"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(log2dict_FILE, \"r\") as file:  \n",
    "    log2dict = json.load(file)   \n",
    "len(log2dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    2785\n",
       "2     358\n",
       "3      31\n",
       "5       8\n",
       "4       7\n",
       "6       4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_matches = []\n",
    "for key in matches.keys():\n",
    "    n_matches.append(len(matches[key]))\n",
    "pd.Series(n_matches).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "798\n"
     ]
    }
   ],
   "source": [
    "all_calls = list(matches.keys())\n",
    "# or\n",
    "nonfocals = []\n",
    "for call in matches.keys():\n",
    "    if pred_dict[call]==1:\n",
    "        nonfocals.append(call)\n",
    "\n",
    "all_calls = nonfocals\n",
    "\n",
    "\n",
    "print(len(all_calls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR=8000\n",
    "answers = []\n",
    "mixer.pre_init(SR, -16, 1, 262144)\n",
    "mixer.init()\n",
    "\n",
    "def load_img(callID):\n",
    "    path = img_dict[callID]\n",
    "    image1 = Image.open(path)\n",
    "    image1 = image1.resize((180 , 120), Image.ANTIALIAS)\n",
    "    img = ImageTk.PhotoImage(image1) \n",
    "    return img\n",
    "\n",
    "def play_music(callID):\n",
    "    path = audio_dict[callID]\n",
    "    mixer.music.load(path)\n",
    "    mixer.music.play()\n",
    "\n",
    "def play_context(callID):\n",
    "    path = context_audio_dict[callID]\n",
    "    mixer.music.load(path)\n",
    "    # start timer\n",
    "    mixer.music.play()\n",
    "\n",
    "def check(letter, view):\n",
    "    answers.append(letter)\n",
    "    with open('answers.txt', 'w') as f:\n",
    "        for call,a in zip(all_calls[0:len(answers)],answers):\n",
    "            item = call+';'+a\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    f.close()\n",
    "    showAnswer(letter, view)\n",
    "    #unpackView(view)\n",
    "\n",
    "def showAnswer(letter, view):\n",
    "    global index  \n",
    "    \n",
    "    label = Label(view, text=\"Your choice: \"+letter)\n",
    "    label.pack()\n",
    "    \n",
    "    callID = all_calls[index]\n",
    "    \n",
    "    algo_choice = \"focal\" if pred_dict[callID]==0 else \"nonfocal\"\n",
    "    label = Label(view, text=\"Algorithm choice: \"+algo_choice+\" (\"+pred_why_dict[callID]+\")\")\n",
    "    label.pack()\n",
    "    \n",
    "    label = Label(view, text=\"(\"+pred_comment[callID]+\")\")\n",
    "    label.pack()\n",
    "                     \n",
    "    button_continue = Button(view, text=\"Continue\", command=lambda *args: unpackView(view))\n",
    "    button_continue.pack()  \n",
    "   \n",
    "    \n",
    "def getView(window):\n",
    "    global index\n",
    "    view = Frame(window)\n",
    "    \n",
    "    callID = all_calls[index]\n",
    "\n",
    "    frm_choice = tk.Frame(master=view, width=650, height=150)\n",
    "    frm_call_spec =  tk.Frame(master=view, width=650, height=150)\n",
    "    frm_specs = tk.Frame(master=view, width=650, height=500)\n",
    "\n",
    "    # frm_choice:\n",
    "    choice_label = Label(master=frm_choice, text=\"Please assign the call of interest\")\n",
    "    choice_label.pack(side=\"top\") \n",
    "    \n",
    "    for choice in ['focal (no_match)', 'focal (match)','nonfocal (match)', 'nonfocal (no_match)']:\n",
    "        button_x = Button(master=frm_choice, text=choice, command=lambda choice=choice: check(choice, view))\n",
    "        button_x.pack(side=\"top\")\n",
    "    \n",
    "    # frm_call_spec:\n",
    "    frm_1spec = tk.Frame(master=frm_call_spec,relief=tk.RAISED,borderwidth=1)\n",
    "    label = tk.Label(master=frm_1spec, text=callID)\n",
    "    label.pack()\n",
    "    \n",
    "    #label = tk.Label(master=frm_1spec, text=str(round(log2dict[callID],2)))\n",
    "    label = tk.Label(master=frm_1spec, text=str(round(intense_dict[callID],2)))\n",
    "    label.pack()\n",
    "\n",
    "    btn_play = Button(master=frm_1spec, text=\"Play sound\",command=lambda callID=callID: play_music(callID))\n",
    "    btn_play.command = lambda callID=callID: play_music(callID)\n",
    "    btn_play.pack(side=\"top\")\n",
    "    \n",
    "    # **************** NEW ***************\n",
    "    if callID in context_audio_dict.keys():\n",
    "        btn_play_context = Button(master=frm_1spec, text=\"Play context\",command=lambda callID=callID: play_context(callID))\n",
    "        btn_play_context.command = lambda callID=callID: play_context(callID)\n",
    "        btn_play_context.pack(side=\"top\")\n",
    "    # **************** NEW ***************\n",
    "    \n",
    "    img = load_img(callID)\n",
    "    lbl_img = Label(master=frm_1spec, image=img)\n",
    "    lbl_img.image = img\n",
    "    lbl_img.pack()     \n",
    "    frm_1spec.pack()\n",
    "\n",
    "    # frm_specs:\n",
    "    spec_names = matches[callID]\n",
    "    n_specs = len(spec_names)\n",
    "    n_rows = int(math.ceil(n_specs/2))\n",
    "\n",
    "    s=0\n",
    "    for i in range(n_rows):\n",
    "        for j in range(2 if n_specs>1 else 1):\n",
    "            frm_1spec = tk.Frame(master=frm_specs)#,relief=tk.RAISED,borderwidth=1)\n",
    "\n",
    "            # callID\n",
    "            label = tk.Label(master=frm_1spec, text=spec_names[s])\n",
    "            label.pack()\n",
    "            \n",
    "            #label = tk.Label(master=frm_1spec, text=str(round(log2dict[spec_names[s]],2)))\n",
    "            label = tk.Label(master=frm_1spec, text=str(round(intense_dict[spec_names[s]],2)))\n",
    "            label.pack()\n",
    "\n",
    "            # Play button\n",
    "            btn_play = Button(master=frm_1spec, text=\"Play sound\",command=lambda callID=spec_names[s]: play_music(callID))\n",
    "            btn_play.command = lambda callID=spec_names[s]: play_music(callID)\n",
    "            btn_play.pack(side=\"top\")\n",
    "            \n",
    "            # **************** NEW ***************\n",
    "            if spec_names[s] in context_audio_dict.keys():\n",
    "                btn_play_context = Button(master=frm_1spec, text=\"Play context\",command=lambda callID=spec_names[s]: play_context(callID))\n",
    "                btn_play_context.command = lambda callID=spec_names[s]: play_context(callID)\n",
    "                btn_play_context.pack(side=\"top\")\n",
    "            # **************** NEW ***************\n",
    "\n",
    "            # Spec img\n",
    "            img = load_img(spec_names[s])\n",
    "            lbl_img = Label(master=frm_1spec, image=img)\n",
    "            lbl_img.image = img\n",
    "            lbl_img.pack()     \n",
    "            frm_1spec.grid(row=i, column=j)\n",
    "            s=s+1\n",
    "\n",
    "    frm_choice.pack()\n",
    "    frm_call_spec.pack(fill=tk.X)\n",
    "    frm_specs.pack(fill=tk.X)\n",
    "    \n",
    "    return view\n",
    "    \n",
    "def unpackView(view):\n",
    "    global window\n",
    "    view.pack_forget()\n",
    "    askQuestion()\n",
    "\n",
    "def askQuestion():\n",
    "    global window, index, button\n",
    "    if(number_of_questions == index + 1):\n",
    "        Label(window, text=\"Thank you. You can close the window.\").pack()\n",
    "        return\n",
    "    button.pack_forget()\n",
    "    index += 1\n",
    "    getView(window).pack()\n",
    "    \n",
    "\n",
    "index = -1\n",
    "right = 0\n",
    "number_of_questions = len(all_calls)\n",
    "\n",
    "\n",
    "window = tk.Tk()\n",
    "window.title('Focal nonfocal resolve quiz')\n",
    "window.geometry(\"800x650\")\n",
    "button = Button(window, text=\"Start\", command=askQuestion)\n",
    "button.pack()\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

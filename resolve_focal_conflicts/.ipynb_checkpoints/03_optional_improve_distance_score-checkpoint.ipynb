{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign distance score interactive\n",
    "\n",
    "Prompts user input for call pairs that cannot be clearly be assigned to same-call or different-call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 2.0.1 (SDL 2.0.14, Python 3.7.10)\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# sound file generation\n",
    "import soundfile as sf\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as sps\n",
    "\n",
    "from tkinter import Tk, Frame, Label, Button, Entry\n",
    "from pygame import mixer\n",
    "from PIL import ImageTk, Image\n",
    "from glob import glob\n",
    "from pandas.core.common import flatten\n",
    "import tkinter as tk\n",
    "from IPython.display import Audio\n",
    "from scipy.spatial import distance\n",
    "import librosa\n",
    "import librosa.display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for later\n",
    "HOME = os.getcwd()+\"/\"\n",
    "OUTDIR = os.getcwd()+\"/\"\n",
    "CANDIDATES_LABELFILE = HOME+\"candidates_labelfile.pkl\"\n",
    "F_NF_FILE = HOME+'f_nf.csv'\n",
    "\n",
    "# Create wav and spec_img folders\n",
    "os.mkdir('resolver_quiz')\n",
    "os.chdir('resolver_quiz')\n",
    "dirs2create = ['wavs', 'spec_imgs']\n",
    "for dirpath in dirs2create:\n",
    "    if not os.path.exists(dirpath):\n",
    "    os.mkdir(dirpath)\n",
    "os.chdir(HOME)\n",
    "    \n",
    "WAV_FOLDER = HOME+\"resolver_quiz/wavs/\"\n",
    "IMG_FOLDER = HOME+\"resolver_quiz/spec_imgs/\"\n",
    "\n",
    "\n",
    "# for now\n",
    "HOME = \"/Users/marathomas/Documents/MPI_work/code/\"\n",
    "OUTDIR = \"/Volumes/MaraMeerkat/\"\n",
    "\n",
    "# these should have been generated with 01_identify_focal_conflicts\n",
    "CANDIDATES_LABELFILE = \"/Volumes/MaraMeerkat/candidates_labelfile.pkl\"\n",
    "# File that contains distance scores between call pairs\n",
    "# generated with 02_assign_distances\n",
    "F_NF_FILE = '/Volumes/MaraMeerkat/f_nf.csv'\n",
    "\n",
    "WAV_FOLDER = \"/Volumes/MaraMeerkat/resolver_quiz/wavs/\"\n",
    "IMG_FOLDER = \"/Volumes/MaraMeerkat/resolver_quiz/spec_imgs/\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "CUTOFF = 0.25 # cutoff score for same-different. Using a very conservative cutoff here in order to avoid false-positives\n",
    "             # I want to correct potential errors and not introduce new ones... thus only label nonfocal if I am pretty\n",
    "             # SURE that this call is the same as another one.\n",
    "RELAX_CUTOFF = 0.35 # Upper bound - only require user input for calls between CUTOFF and RELAX_CUTOFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that pads a spectrogram with zeros to a certain length\n",
    "# Input: spectrogram (2D np array)\n",
    "#        maximal length (Integer)\n",
    "# Output: Padded spectrogram (2D np array)\n",
    "def pad_spectro(spec,maxlen):\n",
    "    padding = maxlen - spec.shape[1]\n",
    "    z = np.zeros((spec.shape[0],padding))\n",
    "    padded_spec=np.append(spec, z, axis=1)\n",
    "    return padded_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3193, 35)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_nf = pd.read_csv(F_NF_FILE, sep=\"\\t\", index_col=0)\n",
    "\n",
    "# labelfile of all potentially conflicting calls\n",
    "labelfile = pd.read_pickle(CANDIDATES_LABELFILE)\n",
    "labelfile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_a</th>\n",
       "      <th>call_b</th>\n",
       "      <th>dist_score</th>\n",
       "      <th>intense_a</th>\n",
       "      <th>intense_b</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>20170806_VHMF001_01_11_08_395_0_00_059_sn</td>\n",
       "      <td>20170806_VHMM003_01_11_23_234_0_00_058_sn</td>\n",
       "      <td>0.276226</td>\n",
       "      <td>-34.027026</td>\n",
       "      <td>-38.562342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>20170806_VHMF001_01_36_14_840_0_00_154_unk</td>\n",
       "      <td>20170806_VHMM003_01_36_30_295_0_00_140_soc</td>\n",
       "      <td>0.338455</td>\n",
       "      <td>-40.511288</td>\n",
       "      <td>-34.945054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>20170806_VHMF001_01_51_44_070_0_00_068_sn</td>\n",
       "      <td>20170806_VHMM006_01_52_14_795_0_00_082_sn</td>\n",
       "      <td>0.341427</td>\n",
       "      <td>-35.694063</td>\n",
       "      <td>-43.931466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>20170806_VHMM002_01_51_57_620_0_00_201_unk</td>\n",
       "      <td>20170806_VHMM006_01_52_22_609_0_00_215_unk_*</td>\n",
       "      <td>0.261807</td>\n",
       "      <td>-45.727865</td>\n",
       "      <td>-36.506488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>20170823_VHMM002_00_49_11_887_0_00_038_sn</td>\n",
       "      <td>20170823_VHMM007_00_49_08_707_0_00_031_sn</td>\n",
       "      <td>0.315335</td>\n",
       "      <td>-38.166317</td>\n",
       "      <td>-14.703301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1806</td>\n",
       "      <td>20190719_VHMF015_01_22_59_568_0_00_124_cc</td>\n",
       "      <td>20190719_VHMM023_01_25_41_897_0_00_150_cc</td>\n",
       "      <td>0.348921</td>\n",
       "      <td>-44.689925</td>\n",
       "      <td>-20.258578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1830</td>\n",
       "      <td>20190719_VHMM007_02_00_24_780_0_00_161_al</td>\n",
       "      <td>20190719_VHMM016_02_00_58_554_0_00_129_al_*</td>\n",
       "      <td>0.272317</td>\n",
       "      <td>-18.133032</td>\n",
       "      <td>-26.727692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1834</td>\n",
       "      <td>20190719_VHMM008_01_57_14_161_0_00_217_fu_cc+s...</td>\n",
       "      <td>20190719_VHMM016_01_56_46_852_0_00_210_fu_cc+agg</td>\n",
       "      <td>0.341091</td>\n",
       "      <td>-33.644835</td>\n",
       "      <td>-13.797516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1835</td>\n",
       "      <td>20190719_VHMM014_01_18_40_546_0_00_136_fu_cc+agg</td>\n",
       "      <td>20190719_VHMM016_01_18_30_400_0_00_123_fu_cc+a...</td>\n",
       "      <td>0.279708</td>\n",
       "      <td>-21.608040</td>\n",
       "      <td>-29.735975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1839</td>\n",
       "      <td>20190719_VHMM021_01_19_42_491_0_00_172_cc</td>\n",
       "      <td>20190719_VHMM023_01_20_05_843_0_00_161_cc</td>\n",
       "      <td>0.314651</td>\n",
       "      <td>-21.421505</td>\n",
       "      <td>-24.152041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>207 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 call_a  \\\n",
       "14            20170806_VHMF001_01_11_08_395_0_00_059_sn   \n",
       "21           20170806_VHMF001_01_36_14_840_0_00_154_unk   \n",
       "27            20170806_VHMF001_01_51_44_070_0_00_068_sn   \n",
       "39           20170806_VHMM002_01_51_57_620_0_00_201_unk   \n",
       "75            20170823_VHMM002_00_49_11_887_0_00_038_sn   \n",
       "...                                                 ...   \n",
       "1806          20190719_VHMF015_01_22_59_568_0_00_124_cc   \n",
       "1830          20190719_VHMM007_02_00_24_780_0_00_161_al   \n",
       "1834  20190719_VHMM008_01_57_14_161_0_00_217_fu_cc+s...   \n",
       "1835   20190719_VHMM014_01_18_40_546_0_00_136_fu_cc+agg   \n",
       "1839          20190719_VHMM021_01_19_42_491_0_00_172_cc   \n",
       "\n",
       "                                                 call_b  dist_score  \\\n",
       "14            20170806_VHMM003_01_11_23_234_0_00_058_sn    0.276226   \n",
       "21           20170806_VHMM003_01_36_30_295_0_00_140_soc    0.338455   \n",
       "27            20170806_VHMM006_01_52_14_795_0_00_082_sn    0.341427   \n",
       "39         20170806_VHMM006_01_52_22_609_0_00_215_unk_*    0.261807   \n",
       "75            20170823_VHMM007_00_49_08_707_0_00_031_sn    0.315335   \n",
       "...                                                 ...         ...   \n",
       "1806          20190719_VHMM023_01_25_41_897_0_00_150_cc    0.348921   \n",
       "1830        20190719_VHMM016_02_00_58_554_0_00_129_al_*    0.272317   \n",
       "1834   20190719_VHMM016_01_56_46_852_0_00_210_fu_cc+agg    0.341091   \n",
       "1835  20190719_VHMM016_01_18_30_400_0_00_123_fu_cc+a...    0.279708   \n",
       "1839          20190719_VHMM023_01_20_05_843_0_00_161_cc    0.314651   \n",
       "\n",
       "      intense_a  intense_b  \n",
       "14   -34.027026 -38.562342  \n",
       "21   -40.511288 -34.945054  \n",
       "27   -35.694063 -43.931466  \n",
       "39   -45.727865 -36.506488  \n",
       "75   -38.166317 -14.703301  \n",
       "...         ...        ...  \n",
       "1806 -44.689925 -20.258578  \n",
       "1830 -18.133032 -26.727692  \n",
       "1834 -33.644835 -13.797516  \n",
       "1835 -21.608040 -29.735975  \n",
       "1839 -21.421505 -24.152041  \n",
       "\n",
       "[207 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select all with distance score between CUTOFF and RELAX_CUTOFF and let them be assigned manually!\n",
    "\n",
    "unclear_df = f_nf.loc[(f_nf['dist_score']>CUTOFF) & (f_nf['dist_score']<RELAX_CUTOFF),:]\n",
    "files_we_need = list(set(list(unclear_df.call_a.values)+list(unclear_df.call_b.values)))\n",
    "labelfile = labelfile.loc[labelfile.callID_new.isin(files_we_need),:]\n",
    "\n",
    "unclear_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate images and wav files for dist score quiz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate wavs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SR = 8000\n",
    "\n",
    "def write_wav(uid, data, sr):\n",
    "    filename = str(uid)+'.wav'\n",
    "    if sr == SR:\n",
    "        sf.write(filename, data, sr, subtype='PCM_16')\n",
    "    else: # resample\n",
    "        #print(\"Resampled for \"+filename)\n",
    "        number_of_samples = int(round(len(data) * float(SR) / sr))\n",
    "        data = sps.resample(data, number_of_samples)\n",
    "        sf.write(filename, data, SR, subtype='PCM_16')\n",
    "        \n",
    "\n",
    "os.chdir(WAV_FOLDER)\n",
    "x=labelfile.apply(lambda row: write_wav(row['callID_new'], row['raw_audio'], row['samplerate_hz']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_spectro(spec,maxlen):\n",
    "    padding = maxlen - spec.shape[1]\n",
    "    z = np.zeros((spec.shape[0],padding))\n",
    "    padded_spec=np.append(spec, z, axis=1)\n",
    "    return padded_spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pylab\n",
    "\n",
    "n_ticks=3\n",
    "FFT_WIN = 0.03\n",
    "FFT_HOP = FFT_WIN/8\n",
    "FMAX = 4000\n",
    "MAX_FRAMES = 100 # all specs smaller than that will be padded\n",
    "                 # all specs longer than that will not be affected\n",
    "\n",
    "def write_img(uid, spec, sr):\n",
    "    HOP_LEN = int(0.03*sr) # this is wrong I think\n",
    "    \n",
    "    \n",
    "    outname = str(uid)+\".jpg\" \n",
    "    plt.figure()\n",
    "    \n",
    "    if(spec.shape[1]<MAX_FRAMES):\n",
    "        spec = pad_spectro(spec,MAX_FRAMES)\n",
    "    librosa.display.specshow(spec,sr=sr, hop_length=HOP_LEN , fmax=FMAX, y_axis='mel', cmap='inferno')\n",
    "    n_frames = spec.shape[1]\n",
    "    duration = FFT_HOP*spec.shape[1]\n",
    "    step_size = round(duration/n_ticks,2)\n",
    "    myticks = np.arange(0,duration, step_size)\n",
    "    plt.xticks([round(x/FFT_HOP,0) for x in myticks], [str(round(x,2)) for x in myticks])\n",
    "\n",
    "    pylab.savefig(outname, bbox_inches=None, pad_inches=0)\n",
    "    pylab.close()\n",
    "\n",
    "os.chdir(IMG_FOLDER)\n",
    "x=labelfile.apply(lambda row: write_img(row['callID_new'],\n",
    "                                        row['denoised_spectrograms'],\n",
    "                                        row['samplerate_hz']), \n",
    "                  axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make audio dict\n",
    "audios = sorted(glob(WAV_FOLDER+'*.wav'))\n",
    "ids = [os.path.basename(x).split('.')[0] for x in audios]\n",
    "audio_dict = dict(zip(ids, audios))\n",
    "\n",
    "# Make imgs dict\n",
    "imgs = sorted(glob(IMG_FOLDER+'*.jpg'))\n",
    "ids = [os.path.basename(x).split('.')[0] for x in imgs]\n",
    "img_dict = dict(zip(ids, imgs))\n",
    "\n",
    "# Make spectrogram dict\n",
    "spec_dict = dict(zip(labelfile.callID_new, labelfile.denoised_spectrograms))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make all pairs\n",
    "all_pairs = []\n",
    "for i in range(unclear_df.shape[0]):\n",
    "    pair = [unclear_df.iloc[i,:].call_a, unclear_df.iloc[i,:].call_b]\n",
    "    all_pairs.append(pair)\n",
    "\n",
    "# list of all dists\n",
    "all_dists = list(unclear_df.dist_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(HOME)\n",
    "SR=8000\n",
    "answers = []\n",
    "dists = []\n",
    "\n",
    "def check(letter, view):\n",
    "    answers.append(letter)\n",
    "    with open('dist_score_improvement.txt', 'w') as f:\n",
    "        for pair, a in zip(all_pairs[0:len(answers)],answers):\n",
    "            item = pair[0]+';'+pair[1]+';'+a\n",
    "            f.write(\"%s\\n\" % item)\n",
    "    f.close()\n",
    "    unpackView(view)\n",
    "    \n",
    "\n",
    "def getView(window):\n",
    "    global index\n",
    "    view = Frame(window)\n",
    "    \n",
    "    dist = all_dists[index]\n",
    "    label = Label(view, text=str(round(dist,4)))\n",
    "    label.pack(side=\"top\")\n",
    "                \n",
    "    label = Label(view, text=\"Same or different call?\")\n",
    "    label.pack(side=\"top\")        \n",
    "        \n",
    "    for choice in ['same', 'different']:\n",
    "        button_x = Button(view, text=choice, command=lambda choice=choice: check(choice, view))\n",
    "        button_x.pack(side=\"top\")\n",
    "    \n",
    "    spacer = Label(view, text=' ')\n",
    "    spacer.pack(side=\"top\")\n",
    "    \n",
    "    info = Label(view, text=all_pairs[index][0])\n",
    "    info.pack(side=\"top\")\n",
    "        \n",
    "    button_m = Button(view, text=\"Play sound\",command=play_music)\n",
    "    button_m.pack(side=\"top\")\n",
    "        \n",
    "    # Show spec\n",
    "    img = show_image()\n",
    "    spec_img = Label(view, image=img)\n",
    "    spec_img.pack(side = \"top\")\n",
    "    \n",
    "    info = Label(view, text=all_pairs[index][1])\n",
    "    info.pack(side=\"top\")\n",
    "    \n",
    "    button_m = Button(view, text=\"Play nb sound\",command=play_nb_music)\n",
    "    button_m.pack(side=\"top\")\n",
    "    \n",
    "    # Show nb spec\n",
    "    nb_img = show_nb_image()\n",
    "    nb_spec_img = Label(view, image=nb_img)\n",
    "    nb_spec_img.pack(side = \"top\")\n",
    "\n",
    "    return view\n",
    "\n",
    "    \n",
    "def unpackView(view):\n",
    "    global window\n",
    "    view.pack_forget()\n",
    "    askQuestion()\n",
    "\n",
    "def askQuestion():\n",
    "    global window, index, button\n",
    "    if(number_of_questions == index + 1):\n",
    "        Label(window, text=\"Thank you. You can close the window.\").pack()\n",
    "        return\n",
    "    button.pack_forget()\n",
    "    index += 1\n",
    "    getView(window).pack()\n",
    "\n",
    "index = -1\n",
    "right = 0\n",
    "number_of_questions = len(all_pairs)\n",
    "\n",
    "mixer.pre_init(SR, -16, 1, 262144)\n",
    "mixer.init()\n",
    "\n",
    "def play_music():\n",
    "    global questions, window, index, button, right, number_of_questions\n",
    "    bout_id = all_pairs[index][0]\n",
    "    path = audio_dict[bout_id]\n",
    "    mixer.music.load(path)\n",
    "    mixer.music.play()\n",
    "    \n",
    "def play_nb_music():\n",
    "    global questions, window, index, button, right, number_of_questions\n",
    "    bout_id = all_pairs[index][1]\n",
    "    path = audio_dict[bout_id]\n",
    "    mixer.music.load(path)\n",
    "    mixer.music.play()\n",
    "\n",
    "def show_image():\n",
    "    global img, index\n",
    "    bout_id = all_pairs[index][0]\n",
    "    path = img_dict[bout_id]\n",
    "    image1 = Image.open(path)\n",
    "    image1 = image1.resize((360 , 240), Image.ANTIALIAS)\n",
    "    img = ImageTk.PhotoImage(image1)\n",
    "    return img\n",
    "\n",
    "def show_nb_image():\n",
    "    global nb_img, index\n",
    "    bout_id = all_pairs[index][1]\n",
    "    path = img_dict[bout_id]\n",
    "    image1 = Image.open(path)\n",
    "    image1 = image1.resize((360 , 240), Image.ANTIALIAS)\n",
    "    nb_img = ImageTk.PhotoImage(image1)\n",
    "    return nb_img\n",
    "\n",
    "    \n",
    "window = Tk()\n",
    "window.title('Meerkat Sound Classification')\n",
    "window.geometry(\"800x650\")\n",
    "button = Button(window, text=\"Start\", command=askQuestion)\n",
    "button.pack()\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in answers and update f_nf table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>call_a</th>\n",
       "      <th>call_b</th>\n",
       "      <th>manual_assignment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>20170806_VHMF001_01_11_08_395_0_00_059_sn</td>\n",
       "      <td>20170806_VHMM003_01_11_23_234_0_00_058_sn</td>\n",
       "      <td>different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>20170806_VHMF001_01_36_14_840_0_00_154_unk</td>\n",
       "      <td>20170806_VHMM003_01_36_30_295_0_00_140_soc</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>20170823_VHMM002_00_49_11_887_0_00_038_sn</td>\n",
       "      <td>20170823_VHMM007_00_49_08_707_0_00_031_sn</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>20170823_VHMM002_01_09_08_832_0_00_046_sn</td>\n",
       "      <td>20170823_VHMM006_01_09_17_840_0_00_057_sn</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>20170823_VHMM002_01_10_43_259_0_00_095_cc</td>\n",
       "      <td>20170823_VHMF001_01_10_59_741_0_00_097_cc</td>\n",
       "      <td>different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>20170823_VHMF001_01_09_54_850_0_00_128_cc</td>\n",
       "      <td>20170823_VHMM007_01_09_35_388_0_00_143_cc</td>\n",
       "      <td>different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>20170824_VHMM002_01_06_03_434_0_00_128_cc</td>\n",
       "      <td>20170824_2_VHMM003_00_58_28_222_0_00_165_cc</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>20170825_VHMM002_01_01_57_014_0_00_122_cc_14</td>\n",
       "      <td>20170825_VHMF001_01_02_17_605_0_00_122_cc_05</td>\n",
       "      <td>same</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>20170825_VHMM007_01_16_01_518_0_00_063_sn</td>\n",
       "      <td>20170825_3_VHMM003_00_03_32_659_0_00_052_sn</td>\n",
       "      <td>different</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>20170825_VHMM007_01_51_31_464_0_00_164_cc_675</td>\n",
       "      <td>20170825_VHMM006_01_51_50_495_0_00_162_cc_292</td>\n",
       "      <td>different</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          call_a  \\\n",
       "0      20170806_VHMF001_01_11_08_395_0_00_059_sn   \n",
       "1     20170806_VHMF001_01_36_14_840_0_00_154_unk   \n",
       "2      20170823_VHMM002_00_49_11_887_0_00_038_sn   \n",
       "3      20170823_VHMM002_01_09_08_832_0_00_046_sn   \n",
       "4      20170823_VHMM002_01_10_43_259_0_00_095_cc   \n",
       "5      20170823_VHMF001_01_09_54_850_0_00_128_cc   \n",
       "6      20170824_VHMM002_01_06_03_434_0_00_128_cc   \n",
       "7   20170825_VHMM002_01_01_57_014_0_00_122_cc_14   \n",
       "8      20170825_VHMM007_01_16_01_518_0_00_063_sn   \n",
       "9  20170825_VHMM007_01_51_31_464_0_00_164_cc_675   \n",
       "\n",
       "                                          call_b manual_assignment  \n",
       "0      20170806_VHMM003_01_11_23_234_0_00_058_sn         different  \n",
       "1     20170806_VHMM003_01_36_30_295_0_00_140_soc              same  \n",
       "2      20170823_VHMM007_00_49_08_707_0_00_031_sn              same  \n",
       "3      20170823_VHMM006_01_09_17_840_0_00_057_sn              same  \n",
       "4      20170823_VHMF001_01_10_59_741_0_00_097_cc         different  \n",
       "5      20170823_VHMM007_01_09_35_388_0_00_143_cc         different  \n",
       "6    20170824_2_VHMM003_00_58_28_222_0_00_165_cc              same  \n",
       "7   20170825_VHMF001_01_02_17_605_0_00_122_cc_05              same  \n",
       "8    20170825_3_VHMM003_00_03_32_659_0_00_052_sn         different  \n",
       "9  20170825_VHMM006_01_51_50_495_0_00_162_cc_292         different  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "manual_assignment = pd.read_csv(HOME+'dist_score_improvement.txt', sep=\";\", header=None)\n",
    "manual_assignment.columns = ['call_a', 'call_b', 'manual_assignment']\n",
    "manual_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "for call_a, call_b, assignment in zip(manual_assignment.call_a, manual_assignment.call_b, manual_assignment.manual_assignment):   \n",
    "    score = 0 if assignment==\"same\" else 1\n",
    "    f_nf.loc[(f_nf['call_a']==call_a) & (f_nf['call_b']==call_b),'dist_score'] = score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwrite existing f_nf file\n",
    "f_nf.to_csv(F_NF_FILE, sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

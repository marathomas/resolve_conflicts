{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identification of focal conflicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script identifies calls that are close in time and could thus be the same \n",
    "call, recorded by multiple recording devices. These calls are pulled from the \n",
    "dataset.\n",
    "\n",
    "Necessary inputs are \n",
    "- the labelfile of all calls (labelfile.csv)\n",
    "\n",
    "Outputs are \n",
    "\n",
    "- the dictionary \"candidates_matches.json\", containing each call with potential matches as key and all its potential matches as values).\n",
    "\n",
    "- Subset of labelfile, containing only the calls contained in the dictionary (either as key or value or both) is saved as \"candidates_labelfile.csv\" \n",
    "\n",
    "Both saved in current working directory. These outputs will be read by subsequent parts of the resolve_focal_conflicts pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json \n",
    "import datetime\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get server path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SERVER = input(\"Enter path to EAS server (e.g. /Volumes or //10.126.19.90 or /home/Documents/MPI_server: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('server_path.txt', \"r\")\n",
    "SERVER = f.read().strip()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(SERVER):\n",
    "    print(\"Invalid server path: \", SERVER)\n",
    "    exit()  \n",
    "    \n",
    "# If someone put a slash or backslash in last position\n",
    "#if SERVER[-1:]==\"/\" or SERVER[-1:]==\"\\n\":\n",
    "#    SERVER = SERVER[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save for later parts of the script\n",
    "#with open('server_path.txt', 'w') as file:\n",
    "#    file.write(\"%s\" % (SERVER))\n",
    "#file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to labelfile generated with 00_1_extract_calls\n",
    "FULL_LABELFILE = SERVER + os.path.join(os.path.sep, 'EAS_shared',\n",
    "                             'meerkat','working','processed',\n",
    "                             'acoustic', 'extract_calls', 'labelfile.csv')\n",
    "\n",
    "\n",
    "HOME = SERVER + os.path.join(os.path.sep, 'EAS_shared',\n",
    "                             'meerkat','working','processed',\n",
    "                             'acoustic', 'resolve_conflicts')\n",
    "# Matching parameters\n",
    "\n",
    "# search for calls with start times <=TIME_THRESH apart\n",
    "TIME_THRESH= 0.1\n",
    "\n",
    "# time factor threshold for how similar in duration two calls have to be to be flagged as possibly the same\n",
    "DUR_FACTOR = 1.3 #(longer call can be max DUR_FACTOR as long as shorter call)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_datetime(timestring):\n",
    "    \"\"\"\n",
    "    Function that gets datetime object from date and time string\n",
    "    string must match one of the given patterns\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    timestring : String\n",
    "                 some string containing a date and time\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : datetime object\n",
    "             the time as datetime object\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> dt = get_datetime(\"2017-08-06 07:49:24\")\n",
    "    \n",
    "    \"\"\" \n",
    "    time_patterns = ['%Y-%m-%d %H:%M:%S.%f', '%Y-%m-%d %H:%M:%S']\n",
    "    for pattern in time_patterns:\n",
    "        try:\n",
    "            return datetime.datetime.strptime(timestring, pattern)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print(\"Date is not in expected format:\", timestring)\n",
    "    \n",
    "    sys.exit(0)\n",
    "    \n",
    "\n",
    "def get_timediff(time1, time2):\n",
    "    \"\"\"\n",
    "    Function that gets time difference between two datetime objects\n",
    "    in seconds \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    time1 : A datetime object\n",
    "    time2 : A datetime object\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Numeric\n",
    "    Time difference in seconds     \n",
    "    \"\"\" \n",
    "    duration = time1-time2\n",
    "    return abs(duration.total_seconds())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in labelfile...\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading in labelfile...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(82264, 26)\n"
     ]
    }
   ],
   "source": [
    "labelfile = pd.read_csv(FULL_LABELFILE, sep=\"\\t\")\n",
    "print(labelfile.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'callID', 'callType', 'color', 'csvFileName', 'date',\n",
       "       'duration', 'entryName', 'focalType', 'hybrid', 'ind', 'isCall',\n",
       "       'labeller', 'noisy', 't0File', 't0GPS_UTC', 'tEndGPS_UTC',\n",
       "       'tMidGPS_UTC', 'unsureType', 'verifier', 'wavFileName', 'x_emitted',\n",
       "       'y_emitted', 'wav_loc', 'start_s', 'duration_s', 'callID_new'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labelfile.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(80011, 26)\n",
      "(73144, 26)\n",
      "(46248, 26)\n"
     ]
    }
   ],
   "source": [
    "# remove zero duration calls\n",
    "labelfile = labelfile.loc[labelfile.duration_s>0,:]\n",
    "print(labelfile.shape)\n",
    "# remove non-calls\n",
    "labelfile = labelfile.loc[labelfile.isCall==1,:]\n",
    "print(labelfile.shape)\n",
    "# remove nonfocal labelled calls\n",
    "labelfile = labelfile.loc[labelfile.focalType!=\"NF\",:]\n",
    "print(labelfile.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify potential matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying potential matches ...\n"
     ]
    }
   ],
   "source": [
    "print(\"Identifying potential matches ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4270essing date:  20190809\n",
      "4270\n"
     ]
    }
   ],
   "source": [
    "# Reduce amount of computation by checking focal-nonfocal pairs per day.\n",
    "all_dates = sorted(list(set(labelfile.date)))\n",
    "match_dict = {}\n",
    "files_dict = {}\n",
    "\n",
    "for date in all_dates:\n",
    "    print(\"Processing date: \", date, end='\\r')\n",
    "    matches = {}\n",
    "    sub_df = labelfile.loc[labelfile.date==date,:]\n",
    "      \n",
    "    # Calculare time distance between all\n",
    "    \n",
    "    callIDs = list(sub_df.callID_new)\n",
    "    durations = list(sub_df.duration_s)\n",
    "    indvs = list(sub_df.ind)\n",
    "    \n",
    "    date_time = [get_datetime(x) for x in sub_df['t0GPS_UTC']]\n",
    "    time_diff_mat = np.zeros((len(date_time), len(date_time)))\n",
    "    \n",
    "    for i in range(len(date_time)):\n",
    "        for j in np.arange(i,len(date_time)):\n",
    "            time_diff_mat[i,j] = get_timediff(date_time[i],date_time[j])\n",
    "            time_diff_mat[j,i] = time_diff_mat[i,j]\n",
    "      \n",
    "    \n",
    "    # Don't want to find pair of call with itself, so I set the diagonal above threshold\n",
    "    for i in range(len(date_time)):\n",
    "        time_diff_mat[i,i] = 999\n",
    "    \n",
    "    # Select all pairs below threshold:\n",
    "    potential_matches = np.nonzero(time_diff_mat<=TIME_THRESH)\n",
    "    \n",
    "    # save potential pairs in two vectors x,y\n",
    "    x = potential_matches[0]\n",
    "    y = potential_matches[1]\n",
    "    \n",
    "    # dict by callID\n",
    "    for i, j in zip(x,y):\n",
    "        \n",
    "        # select only if of different individuals\n",
    "        if (indvs[i]!=indvs[j]):\n",
    "            \n",
    "            # select only if duration diff is below threshold\n",
    "            durs = [durations[i], durations[j]]            \n",
    "            if durs[np.argmax(durs)] <= durs[np.argmin(durs)]*DUR_FACTOR:\n",
    "                \n",
    "                # Note: this allows for \"double entry\" of a call pair, i.e. dict[x] = y AND dict[y] = x\n",
    "                match = [callIDs[i], callIDs[j]]\n",
    "                \n",
    "                # add pair to dictionary if not yet in dictionary\n",
    "                if match[0] not in matches.keys():\n",
    "                    matches[match[0]] = [match[1]]                   \n",
    "                else:\n",
    "                    matches[match[0]] = matches[match[0]]+[match[1]]\n",
    "                    \n",
    "    \n",
    "    files_we_need = []\n",
    "    \n",
    "    for key in matches.keys():\n",
    "        files_we_need.append(key)\n",
    "        for val in matches[key]:\n",
    "            files_we_need.append(val)\n",
    "    files_we_need = list(set(files_we_need))\n",
    "    \n",
    "    match_dict[date] = matches\n",
    "    files_dict[date] = files_we_need\n",
    "\n",
    "\n",
    "all_files_we_need = []\n",
    "all_matches = {}\n",
    "\n",
    "for key in files_dict.keys():\n",
    "    all_files_we_need = all_files_we_need + files_dict[key]\n",
    "    for m_key, m_val in zip(match_dict[key].keys(), match_dict[key].values()):\n",
    "        all_matches[m_key] = m_val\n",
    "        \n",
    "print(len(all_matches)) \n",
    "print(len(all_files_we_need))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates_labelfile = labelfile.loc[labelfile['callID_new'].isin(all_files_we_need)]\n",
    "candidates_labelfile.reset_index(inplace=True, drop=True)\n",
    "\n",
    "candidates_labelfile_out = os.path.join(os.path.sep, HOME,'candidates_labelfile.csv')\n",
    "candidates_labelfile[['callID_new', \n",
    "                      'ind', \n",
    "                      'focalType', \n",
    "                      'entryName', \n",
    "                      'wavFileName', \n",
    "                      'start_s', \n",
    "                      'duration_s',\n",
    "                      'x_emitted',\n",
    "                      'y_emitted']].to_csv(candidates_labelfile_out, sep=\"\\t\", index=False)\n",
    "\n",
    "candidates_matches_out = os.path.join(os.path.sep, HOME,'candidates_matches.json')\n",
    "with open(candidates_matches_out, \"w\") as outfile:  \n",
    "    json.dump(all_matches, outfile)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

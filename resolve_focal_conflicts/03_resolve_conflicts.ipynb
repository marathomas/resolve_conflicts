{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resolve focal conflicts\n",
    "\n",
    "Script to resolve conflicts in labeling (e.g. two calls that overlap in time, are highly\n",
    "similar and none of them has been labelled nonfocal).\n",
    "\n",
    "\n",
    "Requirements:\n",
    "- \"candidates_matches.json\", containing all potential matches (generated with 01_identify_focal_conflicts)\n",
    "- \"candidates_labelfile.csv\", containing audio and spectrogram of all calls involved in a match (generated with 01_identify_focal_conflicts)\n",
    "- \"f_nf.csv\", a csv file containing all pairs of calls and their respective distance score (generated with 02_assign_distance_score)\n",
    "\n",
    "Output:\n",
    "- updates f_nf.csv with intensity scores\n",
    "- generates \"pred_labelfile.csv\", containing the predictions for the candidate calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from scipy import stats\n",
    "import math\n",
    "from scipy.signal import butter, lfilter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('server_path.txt', \"r\")\n",
    "SERVER = f.read().strip()\n",
    "f.close()\n",
    "\n",
    "HOME = SERVER + os.path.join(os.path.sep, 'EAS_shared',\n",
    "                             'meerkat','working','processed',\n",
    "                             'acoustic', 'resolve_conflicts')\n",
    "\n",
    "# location of candidate files generated with 01_identify_focal_conflicts\n",
    "CANDIDATES_MATCHES = os.path.join(os.path.sep, HOME,'candidates_matches.json')\n",
    "CANDIDATES_LABELFILE = os.path.join(os.path.sep, HOME,'candidates_labelfile.csv')\n",
    "\n",
    "# location of file with distance scores generated with 02_assign_distance_score\n",
    "F_NF_FILE = os.path.join(os.path.sep, HOME,'f_nf.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distance score cutoff for deciding which call pairs are same-call vs. different-call\n",
    "# all <= CUTOFF are labelled as same-call\n",
    "CUTOFF = 0.25\n",
    "\n",
    "# Bandpass filters for calculating audio intensity\n",
    "LOWCUT = 300.0\n",
    "HIGHCUT = 3000.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates intensity score from \n",
    "# amplitude audio data\n",
    "# Input: 1D numeric numpy array (audio data)\n",
    "# Output: Float (Intensity)\n",
    "def calc_audio_intense_score(audio):\n",
    "    res = 10*math.log((np.mean(audio**2)),10)\n",
    "    return res\n",
    "\n",
    "# small helper function\n",
    "def which_call_am_I(call,sub_df):    \n",
    "    if call==sub_df.call_a.values[0]:\n",
    "        call=\"a\"\n",
    "        other=\"b\"\n",
    "    elif call==sub_df.call_b.values[0]:\n",
    "        call=\"b\"\n",
    "        other=\"a\"    \n",
    "    return call, other\n",
    "\n",
    "# Butter bandpass filter implementation:\n",
    "# from https://scipy-cookbook.readthedocs.io/items/ButterworthBandpass.html\n",
    "\n",
    "\n",
    "def butter_bandpass(lowcut, highcut, fs, order=5):\n",
    "    nyq = 0.5 * fs\n",
    "    low = lowcut / nyq\n",
    "    high = highcut / nyq\n",
    "    b, a = butter(order, [low, high], btype='band')\n",
    "    return b, a\n",
    "\n",
    "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
    "    b, a = butter_bandpass(lowcut, highcut, fs, order=order)\n",
    "    y = lfilter(b, a, data)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Reading in data...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4270, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labelfile of all candidate matching calls\n",
    "labelfile = pd.read_csv(CANDIDATES_LABELFILE, sep=\"\\t\")\n",
    "labelfile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4270"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary of all candidate calls and their potential matches\n",
    "# (1 call can have multiple matches)\n",
    "with open(CANDIDATES_MATCHES, \"r\") as file:  \n",
    "    matches = json.load(file)\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# table with all call pairs and their respective distance scores\n",
    "f_nf = pd.read_csv(F_NF_FILE, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>call_a</th>\n",
       "      <th>call_b</th>\n",
       "      <th>dist_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>20170806_VCVM001_01_11_05_400_0_00_065_sn</td>\n",
       "      <td>20170806_VHMM003_01_10_57_645_0_00_063_sn</td>\n",
       "      <td>0.608889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20170806_VCVM001_01_11_05_645_0_00_068_sn</td>\n",
       "      <td>20170806_VHMM003_01_10_57_887_0_00_071_sn</td>\n",
       "      <td>0.890803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>20170806_VCVM001_01_11_05_880_0_00_062_sn</td>\n",
       "      <td>20170806_VHMM003_01_10_58_067_0_00_058_sn</td>\n",
       "      <td>0.480133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>20170806_VCVM001_01_11_05_880_0_00_062_sn</td>\n",
       "      <td>20170806_VHMM003_01_10_58_153_0_00_069_sn</td>\n",
       "      <td>0.666613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>20170806_VCVM001_01_12_26_129_0_00_064_sn_x</td>\n",
       "      <td>20170806_VHMM002_01_12_08_899_0_00_066_sn</td>\n",
       "      <td>0.965364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2671</th>\n",
       "      <td>2671</td>\n",
       "      <td>20190809_VLM234_01_20_38_163_0_00_043_sn</td>\n",
       "      <td>20190809_VLM245_01_21_33_006_0_00_054_sn</td>\n",
       "      <td>1.088044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2672</th>\n",
       "      <td>2672</td>\n",
       "      <td>20190809_VLM234_01_20_38_228_0_00_043_sn</td>\n",
       "      <td>20190809_VLM245_01_21_33_006_0_00_054_sn</td>\n",
       "      <td>1.034063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2673</th>\n",
       "      <td>2673</td>\n",
       "      <td>20190809_VLM234_01_20_38_290_0_00_035_sn</td>\n",
       "      <td>20190809_VLM245_01_21_33_098_0_00_036_sn</td>\n",
       "      <td>0.666634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>2674</td>\n",
       "      <td>20190809_VLM234_01_20_38_402_0_00_038_sn</td>\n",
       "      <td>20190809_VLM245_01_21_33_098_0_00_036_sn</td>\n",
       "      <td>0.198532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2675</th>\n",
       "      <td>2675</td>\n",
       "      <td>20190809_VLM245_01_57_02_312_0_00_076_cc</td>\n",
       "      <td>20190809_VLM248_01_57_52_164_0_00_095_unk_*</td>\n",
       "      <td>0.380799</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2676 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                                       call_a  \\\n",
       "0              0    20170806_VCVM001_01_11_05_400_0_00_065_sn   \n",
       "1              1    20170806_VCVM001_01_11_05_645_0_00_068_sn   \n",
       "2              2    20170806_VCVM001_01_11_05_880_0_00_062_sn   \n",
       "3              3    20170806_VCVM001_01_11_05_880_0_00_062_sn   \n",
       "4              4  20170806_VCVM001_01_12_26_129_0_00_064_sn_x   \n",
       "...          ...                                          ...   \n",
       "2671        2671     20190809_VLM234_01_20_38_163_0_00_043_sn   \n",
       "2672        2672     20190809_VLM234_01_20_38_228_0_00_043_sn   \n",
       "2673        2673     20190809_VLM234_01_20_38_290_0_00_035_sn   \n",
       "2674        2674     20190809_VLM234_01_20_38_402_0_00_038_sn   \n",
       "2675        2675     20190809_VLM245_01_57_02_312_0_00_076_cc   \n",
       "\n",
       "                                           call_b  dist_score  \n",
       "0       20170806_VHMM003_01_10_57_645_0_00_063_sn    0.608889  \n",
       "1       20170806_VHMM003_01_10_57_887_0_00_071_sn    0.890803  \n",
       "2       20170806_VHMM003_01_10_58_067_0_00_058_sn    0.480133  \n",
       "3       20170806_VHMM003_01_10_58_153_0_00_069_sn    0.666613  \n",
       "4       20170806_VHMM002_01_12_08_899_0_00_066_sn    0.965364  \n",
       "...                                           ...         ...  \n",
       "2671     20190809_VLM245_01_21_33_006_0_00_054_sn    1.088044  \n",
       "2672     20190809_VLM245_01_21_33_006_0_00_054_sn    1.034063  \n",
       "2673     20190809_VLM245_01_21_33_098_0_00_036_sn    0.666634  \n",
       "2674     20190809_VLM245_01_21_33_098_0_00_036_sn    0.198532  \n",
       "2675  20190809_VLM248_01_57_52_164_0_00_095_unk_*    0.380799  \n",
       "\n",
       "[2676 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate intensity scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Calculating audio intensity scores...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the band-pass filtered signal! \n",
    "\n",
    "clean_intensity = []\n",
    "\n",
    "for call in list(labelfile.callID_new):\n",
    "    audio = list(labelfile.loc[labelfile.callID_new==call,'raw_audio'])[0]\n",
    "    sr = list(labelfile.loc[labelfile.callID_new==call,'samplerate_hz'])[0]\n",
    "    y = butter_bandpass_filter(audio, LOWCUT, HIGHCUT, sr, order=6)\n",
    "    clean_intensity.append(calc_audio_intense_score(y))\n",
    "labelfile['intense_score'] = clean_intensity\n",
    "intense_dict = dict(zip(labelfile.callID_new.values, labelfile.intense_score.values))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add intensity scores to labelfile and f_nf dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_nf['intense_a'] = [intense_dict[x] for x in f_nf.call_a]\n",
    "f_nf['intense_b'] = [intense_dict[x] for x in f_nf.call_b]\n",
    "f_nf.to_csv(F_NF_FILE, sep=\"\\t\", index=False)\n",
    "#f_nf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assign focal or nonfocal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make dataframe of all call pairs, their distance scores and faint scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then assign calls focal or noncal following these hierarchical steps:\n",
    "\n",
    "- 1) Assignment of calls with no high fidelity match (e.g. that were not recognized as \"same-call\")\n",
    "- 2) Assignment of calls that have only one high fidelity match\n",
    "- 3) Assignment of calls that have multiple high fidelity matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Assigning focal/nonfocal...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will save the predictions\n",
    "pred_nonFocal={}\n",
    "# this will save information on WHY prediction was made \n",
    "why_pred = {}\n",
    "# this will save additional information on WHY prediction was made \n",
    "pred_comment= {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Case: Calls with no high fidelity match\n",
    "\n",
    "--> can be assigned focal (why: \"no_match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1863  calls assigned after step 1) no high fidelity match\n"
     ]
    }
   ],
   "source": [
    "for call in labelfile.callID_new.values:    \n",
    "    # if not already assigned\n",
    "    if call not in pred_nonFocal.keys():\n",
    "        # all rows that concern this call\n",
    "        sub_df = f_nf.loc[(f_nf['call_a']==call) | (f_nf['call_b']==call),:]\n",
    "        # all matches of this call        \n",
    "        sub_df_matched = sub_df.loc[sub_df.dist_score<CUTOFF,:]\n",
    "        \n",
    "        # if call has no matches!:\n",
    "        if sub_df_matched.shape[0]==0:\n",
    "            pred_nonFocal[call] = 0\n",
    "            why_pred[call] = \"no_match\"\n",
    "            pred_comment[call] = \"no further info\"\n",
    "\n",
    "print(len(pred_nonFocal), \" calls assigned after step 1) no high fidelity match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Case: Only 1 high fidelity match "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    3a) the match partner is already assigned f/nf or\n",
    "        -->  assign call to the opposite (why: \"partner assigned (focal)\" or \"partner assigned (nonfocal)\")\n",
    "\n",
    "    3b) match partner is not yet assigned\n",
    "         --> assign to nf if weaker, assign to f if stronger (why: \"weaker_1_match\" or \"stronger_1_match\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3895  calls assigned after step 2) ONE high fidelity match\n"
     ]
    }
   ],
   "source": [
    "for call in labelfile.callID_new.values:    \n",
    "    # if not already assigned\n",
    "    if call not in pred_nonFocal.keys():\n",
    "        # all rows that concern this call\n",
    "        sub_df = f_nf.loc[(f_nf['call_a']==call) | (f_nf['call_b']==call),:]\n",
    "        \n",
    "        # all matches of this call\n",
    "        sub_df_matched = sub_df.loc[sub_df.dist_score<CUTOFF,:]\n",
    "        \n",
    "        # if call has exactly 1 match:\n",
    "        if sub_df_matched.shape[0]==1:\n",
    "            me, other = which_call_am_I(call, sub_df_matched)\n",
    "            other_call = sub_df_matched['call_'+other].values[0] \n",
    "            \n",
    "            # if partner already assigned\n",
    "            if other_call in pred_nonFocal.keys():\n",
    "                # assign to opposite\n",
    "                pred_nonFocal[call] = np.abs(1-pred_nonFocal[other_call])\n",
    "                why_pred[call] = \"partner_assigned\"\n",
    "                pred_comment[call] = other_call+\": \"+why_pred[other_call]\n",
    "                \n",
    "            # if partner not already assigned   \n",
    "            else:\n",
    "                #if weaker, assign nonfocal\n",
    "                if intense_dict[call]<=intense_dict[other_call]:\n",
    "                    pred_nonFocal[call] = 1\n",
    "                    why_pred[call] = \"weaker_1_match\"\n",
    "                    pred_comment[call] = str(round(intense_dict[call],2))+\" vs. \"+str(round(intense_dict[other_call],2))+\" (\"+other_call+\")\"\n",
    "                #if stronger, assign focal\n",
    "                else:\n",
    "                    pred_nonFocal[call] = 0\n",
    "                    why_pred[call] = \"stronger_1_match\"\n",
    "                    pred_comment[call] = str(round(intense_dict[call],2))+\" vs. \"+str(round(intense_dict[other_call],2))+\" (\"+other_call+\")\"\n",
    "\n",
    "print(len(pred_nonFocal), \" calls assigned after step 2) ONE high fidelity match\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3)  Case: Multiple high fidelity matches\n",
    "\n",
    "    4a) of which at least ONE (should be only one) is already known to be the focal one\n",
    "        -->  assign call to nonfocal (why: \"match with a focal\")\n",
    "\n",
    "    4b) of which NONE is known to be focal, but\n",
    "\n",
    "        4b1) I am the strongest\n",
    "            --> assign call to focal (why: \"strongest_in_multiple\")\n",
    "\n",
    "        4b2) I am not the strongest\n",
    "            --> assign call to nonfocal (why: \"not_strongest_in_multiple\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4270  calls assigned after step 3) multiple high fidelity matches\n"
     ]
    }
   ],
   "source": [
    "for call in labelfile.callID_new.values:    \n",
    "    # if not already assigned\n",
    "    if call not in pred_nonFocal.keys():\n",
    "        # all rows that concern this call\n",
    "        sub_df = f_nf.loc[(f_nf['call_a']==call) | (f_nf['call_b']==call),:]\n",
    "        # all matches of this call\n",
    "        \n",
    "        sub_df_matched = sub_df.loc[sub_df.dist_score<CUTOFF,:]\n",
    "        \n",
    "        # if call has  >1 match:\n",
    "        if sub_df_matched.shape[0]>1:\n",
    "            all_ids = (list(set(list(sub_df_matched.call_a.values)+list(sub_df_matched.call_b.values))))\n",
    "            all_partners = [x for x in all_ids if x != call]            \n",
    "            partner_assignments = [pred_nonFocal[x] for x in all_partners if x in pred_nonFocal.keys()]\n",
    "            \n",
    "            #  a) if at least 1 partner is assigned focal\n",
    "            # (at least one partner is assigned AND at least one is assigned as focal)\n",
    "            if ((len(partner_assignments)!=0) and (len([x for x in partner_assignments if x==0])>0)):\n",
    "                pred_nonFocal[call] = 1\n",
    "                why_pred[call] = \"match_with_a_focal\"\n",
    "                \n",
    "                focal_partner = [x for x in all_partners if ((x in pred_nonFocal.keys()) and (pred_nonFocal[x]==0))]\n",
    "                pred_comment[call] = focal_partner[0]\n",
    "            # b) no partner is assigned focal\n",
    "            else: \n",
    "                # b1) I am the strongest\n",
    "                if intense_dict[call]==np.max([intense_dict[x] for x in all_ids]):\n",
    "                    pred_nonFocal[call] = 0\n",
    "                    why_pred[call] = \"strongest_in_multiple\"\n",
    "                    pred_comment[call] = str(round(intense_dict[call],2))\n",
    "                # b2) I am not the strongest\n",
    "                else:\n",
    "                    pred_nonFocal[call] = 1\n",
    "                    why_pred[call] = \"not_strongest_in_multiple\"\n",
    "                    pred_comment[call] = str(round(intense_dict[call],2))+\" vs.\"+str(round(np.max([intense_dict[x] for x in all_ids]),2))\n",
    "                    \n",
    "                \n",
    "print(len(pred_nonFocal), \" calls assigned after step 3) multiple high fidelity matches\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "labelfile['pred_nonFocal'] = [pred_nonFocal[x] for x in labelfile.callID_new]\n",
    "labelfile['pred_why'] = [why_pred[x] for x in labelfile.callID_new]\n",
    "labelfile['pred_comment'] = [pred_comment[x] for x in labelfile.callID_new]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# can save as csv (if dropping the array columns)\n",
    "pred_labelfile_out = os.path.join(os.path.sep, HOME,'pred_labelfile.csv')\n",
    "labelfile.drop(columns=[\"raw_audio\", 'denoised_spectrograms', 'spectrograms']).to_csv(pred_labelfile_out, sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Check performance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3006\n",
       "1    1264\n",
       "Name: pred_nonFocal, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"0: assigned focal, 1: assigned nonfocal\")\n",
    "print(labelfile.pred_nonFocal.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>pred_nonFocal</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pred_why</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>match_with_a_focal</th>\n",
       "      <td>0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>no_match</th>\n",
       "      <td>1863</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>not_strongest_in_multiple</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>partner_assigned</th>\n",
       "      <td>477</td>\n",
       "      <td>480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stronger_1_match</th>\n",
       "      <td>530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>strongest_in_multiple</th>\n",
       "      <td>136</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weaker_1_match</th>\n",
       "      <td>0</td>\n",
       "      <td>545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "pred_nonFocal                 0    1\n",
       "pred_why                            \n",
       "match_with_a_focal            0  164\n",
       "no_match                   1863    0\n",
       "not_strongest_in_multiple     0   75\n",
       "partner_assigned            477  480\n",
       "stronger_1_match            530    0\n",
       "strongest_in_multiple       136    0\n",
       "weaker_1_match                0  545"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.crosstab(index=labelfile['pred_why'], columns=labelfile['pred_nonFocal'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

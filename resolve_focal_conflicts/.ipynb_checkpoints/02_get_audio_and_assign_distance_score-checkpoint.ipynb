{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get audio and assign distance score\n",
    "\n",
    "Script to assign distance scores to call pairs using spectrogram comparison. \n",
    "Requirements:\n",
    "- \"candidates_matches.json\", containing all potential matches (generated with 01_identify_focal_conflicts)\n",
    "- \"candidates_labelfile.csv\" of all calls involved in a match (generated with 01_identify_focal_conflicts)\n",
    "- audio_path, folder that contains all audio data\n",
    "\n",
    "Output:\n",
    "- a csv file containing all pairs of calls and their respective distance score (\"f_nf.csv\"), saved in cwd.\n",
    "- may update \"candidates_labelfile.csv\" and \"candidates_matches.json\" if audio for calls can't be found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Get audio and spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import sox\n",
    "import audiofile as af"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# location of candidate files generated with 01_identify_focal_conflicts\n",
    "CANDIDATES_MATCHES = \"candidates_matches.json\"\n",
    "CANDIDATES_LABELFILE = \"candidates_labelfile.csv\"\n",
    "\n",
    "\n",
    "CANDIDATES_MATCHES = \"/Volumes/EAS_shared/meerkat/working/processed/acoustic/extract_calls/candidates_matches.json\"\n",
    "CANDIDATES_LABELFILE = \"/Volumes/EAS_shared/meerkat/working/processed/acoustic/extract_calls/candidates_labelfile.csv\"\n",
    "\n",
    "\n",
    "# Path to folder that contains audio recording files (long wavs) (can be in subdirectories)\n",
    "AUDIOS_PATH = \"/Volumes/EAS_shared/meerkat/archive/rawdata/MEERKAT_RAW_DATA\"\n",
    "\n",
    "# Info about channel in stereo recordings (all soundfoc are stereo)\n",
    "CHANNEL_INFO_PATH = \"/Volumes/EAS_shared/meerkat/working/METADATA/soundfoc_channels.csv\"\n",
    "# Read in channel dictionary (contains info which channel is meerkat recording for stereo files (SOUNDFOC))\n",
    "channel_tab= pd.read_csv(CHANNEL_INFO_PATH, sep=\"\\t\")\n",
    "MEERKAT_CHANNEL = dict(zip(channel_tab.wavFile, channel_tab.meerkatChannel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spectrogramming parameters\n",
    "FFT_WIN = 0.03 # FFT_WIN*samplerate = length of fft/n_fft (number of audio frames that go in one fft)\n",
    "FFT_HOP = FFT_WIN/8 # FFT_HOP*samplerate = n of audio frames between successive ffts\n",
    "N_MELS = 40 # number of mel bins\n",
    "WINDOW = 'hann' # each frame of audio is windowed by a window function (its length can also be\n",
    "# determined and is then padded with zeros to match n_fft. we use window_length = length of fft\n",
    "FMAX = 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(wav_loc, start_s, duration_s):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that that extracts a chunk of audio data from a given wav file\n",
    "    and returns audio and samplerate\n",
    "    If \"SOUNDFOC\" is in filename, assumes that audio is stereo and \n",
    "    looks up the channel with meerkat vocalizations in MEERKAT_CHANNEL dictionary.\n",
    "    If anything fails and audio cannot be written as txt, returns \"failed read\"\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    wav_loc : string\n",
    "              path to wav file\n",
    "    start_s : float\n",
    "              offset in s\n",
    "    duration_s: float\n",
    "                duration in s\n",
    "    Returns\n",
    "    -------\n",
    "        audio: 2D numpy array\n",
    "               audio data\n",
    "        sr   : Numeric\n",
    "               samplerate\n",
    "    \n",
    "    \"\"\"\n",
    "    # SOUNDFOCs are stereo\n",
    "    data = np.asarray([0])\n",
    "    rate = 0\n",
    "    \n",
    "    if ((wav_loc!=\"NA\") and (duration_s>0)):\n",
    "        try:\n",
    "            data, rate = af.read(wav_loc, offset=start_s, duration=duration_s)\n",
    "            \n",
    "            # if signal is stereo\n",
    "            if data.shape[0]==2:\n",
    "                wav_filename = os.path.basename(wav_loc)\n",
    "                \n",
    "                if wav_filename in MEERKAT_CHANNEL.keys():\n",
    "                    channel = MEERKAT_CHANNEL[wav_filename]\n",
    "                else:\n",
    "                    channel = 0\n",
    "                \n",
    "                data = np.asfortranarray(data[channel,:])  \n",
    "                if np.issubdtype(type(data[0]), np.integer):\n",
    "                    data = data.astype('float32')\n",
    "                    \n",
    "        except Exception:\n",
    "            print('Failed_read for ', wav_loc)\n",
    "            pass\n",
    "        \n",
    "    return data, rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mel_spectrogram(data, rate, n_mels, window, fft_win , fft_hop):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function that generates mel spectrogram from audio data using librosa functions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    data: 1D numpy array (float)\n",
    "          Audio data\n",
    "    rate: numeric(integer)\n",
    "          samplerate in Hz\n",
    "    n_mels: numeric (integer)\n",
    "            number of mel bands\n",
    "    window: string\n",
    "            spectrogram window generation type ('hann'...)\n",
    "    fft_win: numeric (float)\n",
    "             window length in s\n",
    "    fft_hop: numeric (float)\n",
    "             hop between window start in s \n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    result : 2D np.array\n",
    "             Mel-transformed spectrogram\n",
    "\n",
    "    Example\n",
    "    -------\n",
    "    >>> \n",
    "    \n",
    "    \"\"\"\n",
    "    n_fft  = int(fft_win * rate) \n",
    "    hop_length = int(fft_hop * rate) \n",
    "        \n",
    "    s = librosa.feature.melspectrogram(y = data ,\n",
    "                                       sr = rate, \n",
    "                                       n_mels = n_mels , \n",
    "                                       fmax = FMAX, \n",
    "                                       n_fft = n_fft,\n",
    "                                       hop_length = hop_length, \n",
    "                                       window = window, \n",
    "                                       win_length = n_fft)\n",
    "\n",
    "    spectro = librosa.power_to_db(s, ref=np.max)\n",
    "\n",
    "    return spectro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4270, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labelfile = pd.read_csv(CANDIDATES_LABELFILE, sep=\"\\t\")\n",
    "labelfile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['callID_new', 'ind', 'focalType', 'entryName', 'wavFileName', 'start_s',\n",
       "       'duration_s'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#labelfile.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all wav filenames that we need to access\n",
    "wavs_we_need = sorted(list(set(labelfile.wavFileName)))\n",
    "\n",
    "# list all filepaths to all available wav files on the server\n",
    "listOfFiles = list()\n",
    "for r, d, f in os.walk(AUDIOS_PATH):\n",
    "    for file in f:\n",
    "        if (file.endswith(\".wav\") or file.endswith(\".WAV\")):\n",
    "            if file[0]!=\".\":\n",
    "                listOfFiles.append(os.path.join(r, file))\n",
    "            else:\n",
    "                pass\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary\n",
    "wav_matches = []\n",
    "no_wav_path = []\n",
    "\n",
    "# Now assign a path to each wav_filename\n",
    "for wav in wavs_we_need:\n",
    "    # Search corresponding wav\n",
    "    matches = [x for x in listOfFiles if wav in x]\n",
    "    \n",
    "    if(len(matches)==0):\n",
    "        # save all where no_wav_path was found in this list\n",
    "        no_wav_path.append(wav)\n",
    "        matches = \"NA\"\n",
    "    # save all matches in wav_matches\n",
    "    wav_matches.append(matches)\n",
    "    \n",
    "# Unlist all to string and choose first match in case there are multiple\n",
    "wav_matches = [x if type(x)==str else x[0] for x in wav_matches]\n",
    "wav_dict = dict(zip(wavs_we_need, wav_matches))\n",
    "\n",
    "# print the missing\n",
    "for i in range(len(no_wav_path)):\n",
    "    print(\"Couldn't find \", no_wav_path[i], \" in AUDIOS_PATH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add path to wavfile to dataframe\n",
    "labelfile['wav_loc'] = [wav_dict[x] for x in labelfile.wavFileName]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this works but it just takes way too long.\n",
    "raw_audio,samplerate_hz = map(list,zip(*[get_audio(loc, start, dur) for loc, start, dur in zip(labelfile.wav_loc,\n",
    "                                                                                              labelfile.start_s,\n",
    "                                                                                              labelfile.duration_s)]))\n",
    "\n",
    "\n",
    "labelfile['raw_audio'] = raw_audio\n",
    "labelfile['samplerate_hz'] = samplerate_hz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4270\n",
      "3226\n"
     ]
    }
   ],
   "source": [
    "# If there are any calls where no audio data was found, remove these from the labelfile and from matches\n",
    "\n",
    "# Which IDs are missing?\n",
    "missing = []\n",
    "for audio, callID in zip(labelfile.raw_audio, labelfile.callID_new):\n",
    "    if audio.shape[0]==1:\n",
    "        missing.append(callID)\n",
    "\n",
    "if len(missing)!=0:\n",
    "    # remove missing from labelfile\n",
    "    labelfile = labelfile.loc[~(labelfile['callID_new'].isin(missing)),:]\n",
    "    \n",
    "    # remove missing from matches\n",
    "    with open(CANDIDATES_MATCHES, \"r\") as file:\n",
    "        cand_matches = json.load(file)\n",
    "    \n",
    "    matches = {}    \n",
    "\n",
    "    # remove the missing calls in the keys\n",
    "    for key in cand_matches.keys():\n",
    "        if key not in missing:\n",
    "            # then remove any missing calls that are present as match partners\n",
    "            match_partners = [p for p in cand_matches[key] if p not in missing]\n",
    "            if len(match_partners)!=0:\n",
    "                matches[key] = match_partners\n",
    "\n",
    "    # save corrected candidate_matches and labelfile\n",
    "    with open(\"candidates_matches.json\", \"w\") as outfile:  \n",
    "        json.dump(matches, outfile) \n",
    "    \n",
    "    labelfile.to_csv('candidates_labelfile.csv')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate spectrograms\n",
    "spectrograms = labelfile.apply(lambda row: generate_mel_spectrogram(row['raw_audio'],\n",
    "                                                                    row['samplerate_hz'],\n",
    "                                                                    N_MELS,\n",
    "                                                                    WINDOW,\n",
    "                                                                    FFT_WIN,\n",
    "                                                                    FFT_HOP), \n",
    "                               axis=1)\n",
    "\n",
    "\n",
    "labelfile['spectrograms'] = spectrograms\n",
    "\n",
    "denoised = [(spectrogram - np.median(spectrogram, axis=0)) for spectrogram in labelfile['spectrograms']]\n",
    "labelfile['denoised_spectrograms'] = denoised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Assign distance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas.core.common import flatten\n",
    "from scipy import stats\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Template matching parameters\n",
    "\n",
    "N_RANDOM_SHUFFLE = 10 # times to randomly shuffle spectrogram for normalization\n",
    "MIN_OVERLAP = 0.9 # short spectrogram has to have at least MIN_OVERLAP with longer spectrogram\n",
    "MAX_F_SHIFT = 0 # max frequency shift allowed when comparing spectrograms (in mel bins)\n",
    "                # Left this in here for the future, but since it's set to zero, I am not allowing \n",
    "                # frequency shift at the moment\n",
    "N_MELS=40 # N_Mels present\n",
    "MEL_BINS_REMOVED_LOWER = 5 # remove lowest MEL_BINS_REMOVED_LOWER mel bins from \n",
    "                           # spectrograms (~all below 300 Hz), probably noise\n",
    "MEL_BINS_REMOVED_UPPER = 5 # remove upmost MEL_BINS_REMOVED_UPPER mel bins from\n",
    "                           # spectrograms (~all above 3 kHz), probably noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec_dist(s_1, s_2):\n",
    "    \"\"\"\n",
    "    Basic spectrogram distance function\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s_1, s_2: 2D np.arrays\n",
    "              the two spectrograms to compare\n",
    "          \n",
    "    Returns\n",
    "    -------   \n",
    "    norm_dist: numeric (Float)\n",
    "               Squared error between specs s_1, s_2\n",
    "               normalized to randomized sq. error \n",
    "               between s_1, s_2\n",
    "    \"\"\"\n",
    "    dist = np.sum((np.subtract(s_1, s_2)*np.subtract(s_1, s_2)), axis=None)\n",
    "    \n",
    "    # Normalize to random shuffling\n",
    "    random_dist = calc_random_dist(s_1,s_2)\n",
    "    norm_dist = dist / random_dist \n",
    "    \n",
    "    return norm_dist\n",
    "\n",
    "def calc_random_dist(s_1, s_2):\n",
    "    \"\"\"\n",
    "    Helper for basic spectrogram distance function\n",
    "    Calculates randomized sq error between two\n",
    "    spectrograms s_1, s_2 by shuffling s_1\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    s_1, s_2: 2D np.arrays\n",
    "              the two spectrograms to compare         \n",
    "    Returns\n",
    "    -------   \n",
    "        numeric (Float)\n",
    "        Randomized sq. error between s_1, s_2\n",
    "    \"\"\"\n",
    "    dists = []\n",
    "    s_1_shuffled = np.copy(s_1)\n",
    "    for i in range(N_RANDOM_SHUFFLE):\n",
    "        np.random.shuffle(s_1_shuffled)\n",
    "        dists.append(np.sum((np.subtract(s_1_shuffled, s_2)*np.subtract(s_1_shuffled, s_2)), axis=None)) \n",
    "    return(np.mean(dists))   \n",
    "\n",
    "def calc_mindist(spec_a, spec_b):\n",
    "    \"\"\"\n",
    "    Calculate min distance between two specs s_1, s_2\n",
    "    by shifting specs against each other along time and \n",
    "    freq axis with certain global constraints\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spec_a, spec_b: 2D np.arrays\n",
    "                    the two spectrograms to compare         \n",
    "    Returns\n",
    "    -------   \n",
    "    min_dist: numeric (Float)\n",
    "              Minimum distance (produced by the best \n",
    "              overlap)\n",
    "    \"\"\"\n",
    "    # Find the bigger spec\n",
    "    spec_list = [spec_a, spec_b]\n",
    "    spec_lens = [s.shape[1] for s in spec_list]\n",
    "    \n",
    "    if spec_a.shape[1]==spec_b.shape[1]:\n",
    "        spec_s = spec_a\n",
    "        len_s = spec_s.shape[1]\n",
    "        spec_l = spec_b\n",
    "        len_l = len_s\n",
    "    else:\n",
    "        spec_s = spec_list[np.argmin(spec_lens)] # shorter spec\n",
    "        len_s = np.min(spec_lens)\n",
    "        spec_l = spec_list[np.argmax(spec_lens)] # longer spec\n",
    "        len_l = np.max(spec_lens)\n",
    "\n",
    "    # define start position for time shifting\n",
    "    # based on MIN_OVERLAP\n",
    "    min_overlap_frames = int(MIN_OVERLAP * len_s)\n",
    "    start_timeline = min_overlap_frames-len_s\n",
    "    max_timeline = len_l - min_overlap_frames\n",
    "\n",
    "    distances = []\n",
    "\n",
    "    # shift short spec across longer, one time frame\n",
    "    # at a time. Only compare the overlap section\n",
    "    for timeline_p in range(start_timeline, max_timeline+1):\n",
    "        # Select full specs or only a subset (start_col to end_col), \n",
    "        # depending on any of the three cases:\n",
    "        \n",
    "        # 1) mismatch on left side\n",
    "        if timeline_p < 0:\n",
    "            start_col_l = 0\n",
    "            len_overlap = len_s - abs(timeline_p)\n",
    "            end_col_l = start_col_l + len_overlap\n",
    "\n",
    "            end_col_s = len_s # until the end\n",
    "            start_col_s = end_col_s - len_overlap\n",
    "\n",
    "        # 2) mismatch on right side\n",
    "        elif timeline_p > (len_l-len_s):\n",
    "            start_col_l = timeline_p\n",
    "            len_overlap = len_l - timeline_p\n",
    "            end_col_l = len_l\n",
    "\n",
    "            start_col_s = 0\n",
    "            end_col_s = start_col_s + len_overlap\n",
    "\n",
    "        # 3) no mismatch on either side\n",
    "        else:\n",
    "            start_col_l = timeline_p\n",
    "            len_overlap = len_s\n",
    "            end_col_l = start_col_l + len_overlap\n",
    "\n",
    "            start_col_s = 0\n",
    "            end_col_s = len_s \n",
    "        \n",
    "        s_s = spec_s[:,start_col_s:end_col_s] \n",
    "        s_l = spec_l[:,start_col_l:end_col_l] \n",
    "        distances.append(spec_dist(s_s, s_l))\n",
    "        \n",
    "        # Now do frequency shift\n",
    "        \n",
    "        # move smaller spec UP\n",
    "        for fshift in range(1,MAX_F_SHIFT+1):\n",
    "            s_s_fshifted = s_s[fshift:,:] # remove lowest freq row(s) from s_s\n",
    "            s_l_fshifted = s_l[:-fshift,:] # remove highest freq row(s) from s_l\n",
    "            \n",
    "            distances.append(spec_dist(s_s_fshifted, s_l_fshifted))\n",
    "        \n",
    "        # move smaller spec DOWN\n",
    "        for fshift in range(1,MAX_F_SHIFT+1):\n",
    "            s_s_fshifted = s_s[:-fshift,:] # remove highest freq row(s) from s_s\n",
    "            s_l_fshifted = s_l[fshift:,:]  # remove lowest freq row(s) from s_l\n",
    "            \n",
    "            distances.append(spec_dist(s_s_fshifted, s_l_fshifted))            \n",
    "        \n",
    "\n",
    "    min_dist = np.min(distances)\n",
    "    return min_dist\n",
    "\n",
    "def preprocess_spec(spec):\n",
    "    \"\"\"\n",
    "    Do some transformations with denoised mel-spectrogram \n",
    "    to improve information content for template matching\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    spec: 2D np.array\n",
    "          a denoised mel-spectrogram      \n",
    "    \n",
    "    Returns\n",
    "    -------   \n",
    "    spec: 2D np.array\n",
    "          the transformed, denoised mel-spectrogram         \n",
    "    \"\"\"\n",
    "    \n",
    "    # Remove MEL_BINS_REMOVED_UPPER and -LOWER mels\n",
    "    spec = spec[MEL_BINS_REMOVED_LOWER:(N_MELS-MEL_BINS_REMOVED_UPPER),:]\n",
    "\n",
    "    # Z-score normalize\n",
    "    spec = stats.zscore(spec, axis=None)\n",
    "    \n",
    "    # Cap vals > 3 STD higher than mean (intense=intense)\n",
    "    spec = np.where(spec > 3, 3, spec)\n",
    "    \n",
    "    #  Cap vals lower than mean to 0\n",
    "    spec = np.where(spec < 0, 0, spec)\n",
    "    \n",
    "    return spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4270, 31)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# labelfile of all potentially conflicting calls\n",
    "#labelfile = pd.read_pickle(CANDIDATES_LABELFILE)\n",
    "#labelfile.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4270"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dictionary of calls and their potential conflicting partners\n",
    "\n",
    "with open(CANDIDATES_MATCHES, \"r\") as file:  \n",
    "    matches = json.load(file)\n",
    "len(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1853\n"
     ]
    }
   ],
   "source": [
    "# list containing all pairs of calls\n",
    "# (non-redundant, i.e. does not contain both [x,y] and [y,x], but only [x,y])\n",
    "\n",
    "all_pairs = []\n",
    "\n",
    "for key in matches.keys():\n",
    "    for val in matches[key]:\n",
    "        if [val,key] not in all_pairs:\n",
    "            all_pairs.append([key, val])\n",
    "        \n",
    "print(len(all_pairs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calc dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_dict = dict(zip(labelfile.callID_new.values, labelfile.denoised_spectrograms.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists=[]\n",
    "\n",
    "for pair in all_pairs:\n",
    "    spec = preprocess_spec(spec_dict[pair[0]])\n",
    "    nb_spec = preprocess_spec(spec_dict[pair[1]])\n",
    "    dist = calc_mindist(spec, nb_spec)\n",
    "    dists.append(dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save dataframe of all call pairs and their distance scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_nf = pd.DataFrame({'call_a': [x[0] for x in all_pairs],\n",
    "                    'call_b' : [x[1] for x in all_pairs],\n",
    "                    'dist_score' : dists})\n",
    "\n",
    "f_nf.to_csv(\"f_nf.csv\", sep=\"\\t\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
